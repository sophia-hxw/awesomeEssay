# Focal Loss for Dense Object Detection

## 论文纯翻译

### 摘要

最近准确率较高的检测器是基于RCNN的二阶段检测器，由作用在稀疏待选框上的分类器组成。相比之下，一阶段的检测器是在可能有对象的位置进行规律而密集的采样，会更快，也更简单，但迄今为止会在准确率上落后二阶段的检测器。

本文分析上述成因，发现在使用密集对象训练时遇到的前景、背景间的极度不平衡可能是核心的问题。由此我们提出了通过交叉熵的变体来重置较好分类对象的loss值，来解决类别不均衡的问题，提出了新颖的Focal Loss，聚焦于在一系列稀疏的困难样本上训练，避免大量易分类样本在训练时的压倒性优势。为了评价loss的有效性，我们设计和训练了一个简单的稠密检测器，命名为RetinaNet。结果表明，有了focal loss，RetineNet可以匹敌一阶段的速度，但是准确率却远超所有sota的二阶段检测器。

[code](https://github.com/facebookresearch/Detectron)

---

### 介绍

目前sota的目标检测器是基于二阶段、proposal驱动的机制。比如流程的RCNN为主的框架，第一阶段生成一个目标候选位置的稀疏集合，第二阶段用CNN网络将候选位置分类为前景或背景。由于一系列的优点，二阶段的架构始终在COCO benchmark上霸榜。

尽管二阶段的检测器很成功，一个自然的问题仍然会产生：一个简单的一阶段的检测器也可以达到这个精度么？一阶段的检测器是作用在规律而密集的不同位置，尺度，和长宽比的对象采样上。最近在一阶段上的检测器，诸如YOLO和SSD，得到了有潜力的结果，产出了更快的检测器和对比二阶段大约10%-40%落差的准确率。

本文基于上述工作，提出了一个一阶段的检测器，第一次可在COCO　AP上匹敌更复杂的sota的二阶段检测器，比如FPN和Faster RCNN变形得到的Mask RCNN。为了达到这个效果，我们直面阻碍一阶段检测器达到sota结果的最大绊脚石，即类别不均衡，提出了新的loss函数来消除这个阻碍。

类别不均衡是在类RCNN二阶段的级联检测器中做启发式采样时提出的，proposal的阶段(Selective Search, EdgeBoxes, DeepMask, RPN)会迅速减少候选对象位置的数量到1~2k，过滤掉大部分的背景采样。在第二个分类的阶段，启发式采样，比如固定的前/背景比例(1:3)，线上困难样本挖掘(OHEM)，都会背用来平衡前景和背景的不均衡问题。

相比之下，一阶段的检测器需要处理大批量的、从图像中规律采样的候选对象位置。实践中这个数量一般是~100k的级别，包含了所有的空间位置、尺度和长宽比。虽然类似的启发式采样在训练流程中应用是低效的，但还是由于后续能简单区分背景类别而占了主导地位。目标检测中的这个低效是一个典型问题，经常会用boostrapping或者困难样本挖掘来解决。

文本中，我们提出了一个新的loss函数，相较之前的解决方案能更有效的解决类别不均衡问题。这个loss函数能动态调整交叉熵损失，随着目标分类正确的置信度增长，调整系数会衰减到零。直观上看，调整系数可以在训练过程中自动给容易样本降低loss权重，这样同时也能促使模型更快的作用在困难样本上。实验表明，我们提出的Focal Loss让我们训练处了一个高准确率的一阶段检测器，表现远优于之前sota的一阶段检测器中所使用的启发式采样的训练或者困难样本挖掘。最后，focal loss的确切形式不是最重要的，我们发现其他的实例化也可以获得类似的效果。

为了证明提出的loss是有效的，我们设计了一个简单的一阶段检测器，即RetinaNet，在输入图片上进行目标位置的密集采样。该网络设计了特征金字塔并使用了锚box，灵感源自于近期的几篇文章。RetinaNet是有效而准确的，最好的模型ResNet-101-FPN backbone，在COCO的测试集上获得了39.1的AP，速度是5fps，远高于现已经公开的任何一阶段或二阶段模型。

---

### 相关工作

#### 经典的目标检测器

sliding-window+分类器应用在一系列不同尺寸的图片上，作为目标检测器有较长和丰富的历史。最早的经典工作就是LeCun的工作，将CNN用在手写体的识别上。Viola和Jones将目标检测器用在人脸检测上，引领了这些模型的广泛应用。HOG特征和完整的通道特征在行人检测上产生了很多高效的模型。DPMs将密集的目标检测器拓展到了更一般目标种类，也霸榜PASCAL多年。当sliding-window称为经典机器视觉中目标检测的主线路，深度学习开始复兴了，下面要介绍的二阶段的检测器很快就攻占了目标检测领域。

#### 二阶段检测器

现代目标检测的主流方法是两阶段方法，最早是Selective Search工作，第一个阶段生成大批量包含所有目标的候选框，然后过滤掉大部分的背景得到一个候选框的稀疏集，第二个阶段对上阶段得到的候选框稀疏集进行分类，得到背景或前景的标签。RCNN将第二阶段的分类器整合到CNN网络中，在准确率上获得较大提升，也引领了现代的目标检测领域。RCNN的提升经历了多年的探索，包括速度上和使用目标候选框的学习。RPN(Region Proposal Networks)整合了候选框的生成和第二阶段的分类器到同一个卷积网络中，也促使了Faster RCNN框架的产生，大批量基于此的架构也自此逐渐浮现。

#### 一阶段检测器

OverFeat是深度网络兴起后，目标检测领域的第一个一阶段模型。更近的是YOLO和SSD系列，刷新了一阶段的网络。这些检测器在速度上表现亮眼，但是是以牺牲部分准确率为代价，比如SSD的AP降低了10%到20%，而YOLO在速度和准确率权衡上做的妥协就更多了。近期很多工作表明二阶段的检测器可以用过改变图片的分辨率和候选框的数量来简单提速，但是一阶段的方法即使在较大分辨率的图片上也会逊色于准确率参数。相较之下，本文的目的在于，理解是否一阶段检测器可以在相似或者更快的速度下匹敌或者超过二阶段检测器的准确率。

RetinaNet参考了很多之前密集检测器的设计，比如RPN提出的anchor，SSD和FPN都使用了的特征金字塔。我们一再强调，这个简单检测器的优势不在于网络的创新设计，而是最新设计的loss函数。

#### 类别不均衡

不管是诸如boosted检测器、DPMs或者是像SSD等近期的检测器，都会面临训练时样本不均衡的问题。这些检测器平均每张图片需要预测1w~10w个候选位置，但实际上只有极少数的位置是真正有对象的。样本不均衡会造成两个问题：1，多数位置都是简单的负样本，会造成训练无效；2，多数情况下，简单的负样本会在训练中占压倒性比例，影响模型的泛化能力。通常的解决方法是使用困难样本、其他复杂的样本采集或权重再定义策略。相比之下，本文展示了loss函数可以自然的解决一阶段模型中的类别不均衡问题，可以日常训练所有的样本而不用采样，不会有过多的简单负样本来更新loss或回传梯度。

#### 鲁棒性评价

当然也会有很多人的兴趣点再重新设计更鲁棒的loss函数上，意图减少离群点(较大误差的点，即困难样本)的权重来降低其贡献。相比于找出离群点(困难样本)，focal loss是降低类别不均衡中的内点(简单样本)权重，这样尽管简单样本数量大，但让人会被减少对整个loss的贡献。换句话说，focal loss从鲁棒loss的相反方向来思考，让训练更集中在困难样本上。

---

### Focal Loss

Focal Loss是为了解决一阶段检测器中的前景和背景间的不均衡(比如1:1000)问题，首先回顾下二分类的交叉熵损失(CE)：
$$
CE(p,y)=\begin{cases}
-log(p) & if \quad y = 1\\
-log(1-p) & otherwise.
\end{cases}
$$
在上面的 $$ y \in \{+1,-1\} $$表示 ground truth的类别标签，$$ p \in [0,1] $$是模型在$$y=1$$时的预测结果值，为了方便记录，定义：
$$
p_{t}=\begin{cases}
p & if \quad y=1 \\
1-p & otherwise.
\end{cases}
$$
那么CE损失可以重写为: $$CE(p,y) = CE(p_{t}) = -log(p_{t})$$.

前面的图像figure.1中，最上面，$$\gamma=0$$即是CE损失的图像，从图像中看出，当$$p_{t}>>.5$$时，loss是个相对较大的非零值。如果有很多个这样的易分类样本，聚小成大，对loss的影响就会导致模型在某些类别上的表现有压倒性优势。

#### Balanced交叉熵

交叉熵中常用一个系数$$\alpha$$来调整类别1，用系数$$1-\alpha$$来调整类别-1，实际中$$\alpha$$可能会频繁被另一个类别颠倒或者在交叉验证时被当作一个超参数。为了记录方便，类似$$p_{t}$$来定义定义$$\alpha_{t}$$，由此重写$$\alpha$$-balanced交叉熵：
$$
CE(p_{t}) = -\alpha_{t}log(p_{t})
$$
这就是CE函数的简单拓展，作为我们设计focal loss的基础。

#### Focal Loss定义

我们的实验能够得到的结论，会在密集候选框检测器训练时遇到大的类别不均衡问题，导致密集对象会在交叉熵损失有压倒性优势，容易分类的样本占了loss的大多数并主导着梯度的回传。尽管$$\alpha$$会平衡前景和背景样本，但是它无法区分容易还是困难样本。相应的，我们提出了对loss函数进行变形来降低易分类样本的loss权重，让训练更聚焦在困难样本上。

在交叉熵的公式上，我们提出了新增一个调节参数$$(1-p_{t})^{\gamma}$$，其中$$\gamma \geq 0$$是可调试的聚焦参数，定义focal loss函数：
$$
FL(p_{t}) = -(1-p_{t})^{\gamma}log(p_{t})
$$
focal loss有两个特性：第一，当样本分类错误且$$p_{t}$$较小时，调整参数近似等于1，其loss基本不会有影响。当$$p_{t}\to 1$$，调整参数近似等于0，所以分类较好的样本其loss的权重会被大大降低；第二，聚焦参数$$\gamma$$平滑的适应易分类样本的loss权重下调。当$$\gamma = 0$$，FL等于CE，随着$$\gamma$$的增大，调整参数的影响也会类似的增大，实验中发现$$\gamma$$最好的参数为2.

直观地，调增参数减小了易分类样本的权重，当样本的loss较小时拓宽了其取值范围。比如，$$\gamma = 2$$时，若样本的分类置信度$$p_{t}=0.9$$，相较CE loss，此处的loss会降低100倍，而这个数值会变成100倍，当$$p_{t} = 0.968$$时。这种特性反过来又会增加分错样本的重要性，focal loss在$$p_{t} \leq .5$$和$$\gamma = 2 $$时的loss被减小了4倍以上。

时间中，我们使用的是带$$\alpha$$平衡的focal loss的变形：
$$
FL(p_{t}) = -\alpha_{t}(1-p_{t})^{\gamma}log(p_{t})
$$
我们的实验可看出，没有$$\alpha$$平衡参数时的模型效果也有小小的提升。最终，我们注意到，loss层在框架中的实现紧跟着sigmoid操作，进一步增强了数值稳定性。

我们的实验结果都是基于focal loss的，具体的公式形式不重要，在附录中的其他方式也有用到focal loss，其中的实验证明了其有效性。

#### 3.3 类别不均衡和模型初始化

二分类的模型在初始化时不管样本的$$y=1$$或者$$y=-1$$，都会给相等的概率值。在这样的初始化方式下，当类别不均衡出现时，频繁出现的类别会成为loss的主导，而且容易造成早期训练不稳定的问题。为了应对这个问题，我们让模型在训练初期遇到较少的前景时会给出较高优先级，用$$\pi$$来表示这个优先级，在遇到较少的前景对象时，会让计算出的$$p$$时一个较小值，比如0.01，这是在模型初始化上的变化，而不是loss函数的。在训练时遇到严重的类别不均衡问题时，无论是交叉熵还是focal loss都可以用这个方式来提高稳定性。

#### 3.4 样本不均衡和二阶段检测器

二分类的检测器通常直接用的交叉熵损失，既没有$$\alpha$$平衡系数，也没有使用我们提出的focal loss。通过两种机制来解决类别不均衡问题：第一，二阶段的级联；第二，偏置小批量采样(minibatch sampling)。第一个级联是给出候选proposal，将可能的目标位置从几乎无限减少到1k~2k。需要指出的是，候选框并不是随机选择的，是根据真是目标的位置选择的，去掉了大部分的简单负样本。训练第二个阶段时，偏置采样会被典型应用在小批量的样本上，比如1:3的正负样本比例。这个比例值其实有点类似$$a$$平衡系数的作用，在具体采样时进行调控。本文提出的focal loss会通过loss设计将这些策略直接用在一阶段的检测器。

### 4 Retina net检测器

RetinaNet是一个一阶段的、完整的网络，有backbone和两个特定任务的子网络。backbone的作用是通过一个完整图片输入得到特征图。第一个子网络是在backbone输出的基础上进行目标分类，第二个子网络是做bbox回归。在本文的一阶段、密集检测任务中，这两个子网络设计很简单。当然，这些组成部分后面有详细介绍，大部分的设计中参数在实验中都表现得对具体值并不敏感，下面介绍RetinaNet的每一个网络细节。

##### 特征金字塔网络backbon

将FPN用在RetinaNet的backbone上，FPN在普通的CNN基础上，接受一个单尺度的输入图片，有一个自定向下的特征路径并在同尺度的特征图上进行横向连接，所以网络会有丰富的、多尺度的特征金字塔。每个特征金字塔层都可在不同的尺度上进行目标检测。FPN在FCN的基础上提高了多尺度的检测，还有RPN和DeepMask风格的proposal，跟Fast RCNN和Mask RCNN等二阶段检测器一样表现优异。

本文将FPN的结构用在ResNet上，构建了$$P_{3}$$到$$P_{7}$$的特征金字塔，$$P_{l}$$中的$$l$$表示金字塔的层级，也表示当前的特征图在分辨率上较输入减少了$$2^{l}$$倍。在FPN网络中，所有金字塔层级的最终输出通道都是256，本文在应用时有些微的差别。其他的设计都是常规的，FPN的backbone选择很重要，因为在预备实验中，我们仅使用了ResNet的最后一层，结果模型的AP很低。

##### anchors

本文使用FPN中RPN类似对于anchor的策略，$$P_{3}$$到$$P_{7}$$对应的anchor面积为$$32^{2}$$和$$512^{2}$$，每个特征层使用的anchor有三个长宽比$$\{1:2, 1:1, 2:1\}$$。作为FPN的密集采样，在原有长宽比的基础上，本文新增了$$\{2^{0}, 2^{1/3}, 2^{2/3}\}$$，上述修改提高我最终的AP。每个层最多有$$A=9$$个anchor，能覆盖输入图像$$32\to813$$的像素大小。

每个anchor有一个K one-hot向量，其中K表示目标的种类数，有维度为4的位置向量。本文使用修改过的RPN中的分配策略，稍作修改以使用多分类和阈值。特别的，anchor与gt之间的匹配似乎用IoU和0.5作为阈值来判定，面积交并比小于0.4的就是背景。每个anchor最多匹配一个目标框，相应的类别在K长度的ont-hot向量中为1，其他位置为0.如果一个anchor没有匹配到gt，可能面积的交并比在0.4到0.5之间，在训练时会被忽略。框的回归时计算anchor到与之匹配的gt之间的偏移量，如果没有匹配的gt则省略。

##### 分类子网络

作用是对每个空间位置的A个anchor进行K个种类的目标预测，是关联到FPN每层后面的小FCN网络，所有的FPN层共享这个分类子网络的权重。设计很简单，输入是金字塔层中C个通道的特征层，其后是$$\{3x3\}$$的卷积和ReLU激活，气候再是K*A个$$\{3x3\}$$的卷积。最后的sigmoid会直接给出每个空间位置的二分类输出，本文中$$C=256$$且$$A=9$$.

跟RPN不一样的是，本文的对象分类网络更深，仅使用$$3x3$$的卷积，不与Box回归共享参数，同时也发现，这些高层的设计比特定的超参数更重要。

##### Box回归子网络

与分类子网络平行的就是另一个小的FCN网络，即box回归网络，存在gt的情况下，预测anchor到gt的偏移量。归回子网络是个单独的CNN网络，除非这个偏移量是线性的。不同于其他的工作，本文的bbox回归是在不知道box类别的情况下，使用的参数越少，但是效果一样。分类子网络和box回归子网络是相同的结构，各自有不同的参数。

#### 4.1 推理和训练

##### 推理

RetinaNet由一个单独的FCN组成了ResNet-FPN的backbone，一个分类子网络和一个box回归子网络。所以，infer包括输入图片简单的前传网络。为了提速，每个FPN层只采用top-scoring的1k个框，其后有一个0.05的阈值。所有顶层的预测被整合到一起了，然后用阈值为0.5的NMS之后做出最终的预测结果。

##### Focal Loss

本文使用的就是前文介绍的用于分类子网络的focal loss.当$$\gamma \in [0.5, 5]$$时，focal loss的表现较好，最好的情况是$$\gamma =2$$。训练RetineNet时，focal loss用在每个图平均约采样100k的anchor中，这与使用RPN中使用的启发式采样和困难样本挖掘(OHEM和SSD)不太一样，后者需要选择一个较小的anchor集(如，256)作为批量batch.每张图片的总focal loss是约100k的anchor的损失和，用能匹配到gt的anchor数进行归一化。为什么用可匹配到gt的anchor数量进行归一化，而不是所有的anchor数量呢？因为大部分的anchor都是易分类样本，在focal loss下的损失几乎都可以忽略不计。调整参数$$\alpha$$，少样本的权重调整参数，也有一个稳定的范围，但是其取值与$$\gamma$$相关。通常的做法是，$$\alpha$$在$$\gamma$$递增时进行适量衰减，本文给出的参数是$$\gamma = 2$$，$$\alpha = 0.25$$。

##### 初始化

实验中使用了两个backbone: ResNet-50-FPN和ResNet-101-FPN，ResNet-50和ResNet-101是在ImageNet1k上预训练的模型，新增加的FPN的层用相应的数据来初始化。除了RetinaNet的最后一个子网络，所有新的卷积层都使用偏置$$b=0$$，$$\sigma =0.01$$的高斯分布。最后的分类子网络卷积层，$$b=-log((1-\pi)/\pi)$$，其中$$\pi$$指示出前景样本，因为其置信度约等于$$\pi$$。尽管结果并不太与$$\pi$$的具体值相关联，因此在所有实验中取$$\pi=0.01$$。上文中解释了，本文的初始化阻止了大批量的背景anchor来破坏loss的真实呈现，尤其是在训练的初期。

##### 优化

RetinaNet使用随机梯度下降(SGD)训练的，在8块GPU上同步训练，每块GPU的minibatch是2张图片，所以整体来看的minibatch是16张图片。除非特别说明，所有模型都训练90k个迭代次数，初始学习率为0.01，在60k时学习率为0.001，在80k时的学习率为0.0001，数据增强也就使用了水平增强。权重衰减参数为0.9，衰减0.0001，训练的总loss是focal loss和box回归中使用的标准$$L_{1}$$ loss之和，训练时长大概是10-35个小时。

### 5 实验

评价是在COCO benchmark上，训练使用的是常规方式，训练集是COCO trainval35k，验证集是minival的一部分。我们主要的结果是在test-dev上的，指标是COCO AP。

#### 5.1 训练密集检测器

本文用不同的优化策略实验了很多次来分析focal loss的表现，所有的实验使用的是深度为50或者101的ResNet，也使用了特征金字塔，图片的分辨率尺度为600像素。

##### 网路初始化

第一个尝试是用原始的CE loss来训练RetinaNet，不做任何改变，这很快就失败了，模型不收敛。但是，在我们模型的最后一层做简单初始化，比如检测到一个对象，置$$\pi=0.01$$会使训练有效。训练ResNet-50的RetinaNet在COCO上达到了$$AP=30.2$$，结果对$$\pi$$并不敏感，所以在所有的实验中都使用$$\pi=.01$$。

##### 平衡交叉熵

下一个尝试是平衡交叉熵，带平衡参数$$\alpha$$。当参数$$\alpha=.75$$时，可以获得0.9AP的提升。

##### Focal Loss

focal loss的实验结果可参见表格，同时focal loss引入了一个新的超参数，集聚焦参数$$\gamma$$。当$$\gamma =0$$，focal loss也蜕变成CE loss，当$$\gamma$$增长，loss函数的形状发生变化，简单样本的loss被抑制得更小，如图一。Focal Loss可以看出，随着$$\gamma$$增长，相对CE loss的优势更大。当$$\gamma=2$$时，FL相对平衡交叉熵会有2.9 AP的提升。

见表格1b，为了实验的公平比较，我们给每个$$\gamma$$参数挑选出了最佳的调账参数$$\alpha$$，我们发现，一般较小的$$\alpha$$匹配较大的$$gamma$$。总的来看，改变$$\gamma$$的影响更大，但是仍旧可以得到的结论是，$$\alpha$$的变化区间是$$[.25, .75]$$。所以实验中我们使用的是$$\alpha=.25$$且$$\gamma=2$$。

##### Focal Loss 的分析

为了更好的理解focal loss，我们实验分析了一个收敛模型的损失分布。使用ResNet-101-FPN-600，参数$$\gamma=2$$，$$AP=36.0$$，我们将此模型用在大量的随机图片上，采样约$$10^{7}$$的负样本和约$$10^{5}$$的正样本。下一步，分开讨论正负样本，计算FL值，对损失做归一化之后求和。对归一化的loss，排序后画了图4所示的累积分布函数(简称CDF)。

正负样本的累计分布函数如图4，观察正样本，对不同的$$\gamma$$有类似的图像，将近20%的困难正样本占了一半的正样本loss，当$$\gamma$$增大，越多的损失进入了这20%的样本，但是影响就越小。$$\gamma$$在负样本上的影响却相差比较大，$$\gamma=0$$时，正负样本的CDF都是类似的。然而，随着$$\gamma$$增大，基本上更多的权重都集中到困难负样本上了。实际上，当$$\gamma=2$$，大部分的损失来源于少部分的样本。图像可以看出，FL能影响简单样本的影响，让更多的注意力放到困难负样本上。

##### OHEM(Online Hard Example Mining)

31号文件提出，可以用高loss的样本构建minibatch来提高二阶段模型的训练，比如，OHEM就是用loss给样本排序，之后应用NMS，再选择较高loss的样本组成minibatch，其中，NMS的阈值和minibatch的具体参数是可调的超参数。像focal loss一样，OHEM让训练更多集中在分类错误的样本，不同的是，OHEM对简单样本直接丢弃。同时，OHEM在SSD中有一个变体应用，在应用了nms之后，使用1:3的正负样本比来组成minibatch，以保证足够的正样本。

在我们的一阶段网络中也测试了OHEM来应用类别不均衡问题，表格1d中展示了原生OHEM和$$OHEM 1:3$$中nms和minibatch的参数。实验中使用的模型是ResNet-101，FL的结果是$$AP=36$$，相应的OHEM的AP=32.8，batch=128， nms=.5。在密集检测器中，OHEM较FL低3.2个AP。我们也使用了OHEM其他的参数和变体，但是并没有获得更好的结果。

##### Hinge Loss

最后，在早期实验中，我们也尝试了用hinge loss来训练，对特定的$$p_{t}$$的loss为零。然而，这个做法并不稳定，也没有获得有意义的结果。其他loss函数的尝试可参见附录。

#### 5.2 模型框架设计

##### anchor 密度

一阶段网络设计时一个重要的考虑因素就是box覆盖图片的空间位置，二阶段网络由于由RPN(region proposal network)可以在任意的位置、尺度、长宽比对目标进行检测，而一阶段网络就智能固定一个采样网格，一个流行的且能获得高覆盖率的做法就是在同一位置使用不同的尺度、长宽比的anchor。

对FPN中每个金字塔层中的每个空间点的anchor尺度和长宽比数量也进行了实验论证，从一个正方形anchor到每个位置12个anchor包含4个尺度($$2^{k/4}$$, $$k \leq 3$$)和三个长宽比(0.1, 1, 2)，结果参见1c表格。仅使用一个正方形anchor时的AP=30.3，让我们很惊喜，然而，使用3个尺度和3个长宽比时的AP还可以增长4个点。所以，本文中其他的实验都使用这个配置。

最后，也注意到，大于6-9个anchor之后的模型没有更多的提高了，因为在二阶段的网络里，如果能分类图片中任意位置的框，则性能达到饱和，换一种说法，密度表示了二阶段网络能达到的最好效果，再增加密度则不再有二阶段相对一阶段的优势。

##### 速度 vs 准确率

大的backbone能获得更好的准确率，同时也会降低速度，输入图片尺寸的大小变化也有类似的规律，表格1e中展示这两个参数的影响。图像2给出了RetinaNet的准确率、速度曲线，并与最近的方法在COCO test-dev上进行了比较。图像显示，本文的RetinaNet和focal loss远超其他方法，当然忽略准确率而一味追求速度的模型不在考虑的范围内。输入为600且backbone为ResNet-101-FPN的RetinaNet足以匹配对应的Faster R-CNN，但是122ms对比172ms(Nvidia M40) 的每帧运行时长就有优势了。若增大图片的尺寸，准确率可以优于所有的二阶段检测器，而且更快。若要更快，就只能用ResNet-50-FPN来替换ResNet-101-FPN了，所以如果要高帧率运行，需要独特的网络设计，可以参考其他的文献。同时我们也注意到，在本文发表后，有更多更快、准确率更高的Faster R-CNN网络已经公开。

#### 5.3 对比sota

我们在COCO test-dev上与当前最优的一阶段和二阶段网络进行对比，对比当前最好的一阶段方法，如DSSD，RetinaNet有5.9个点的优势，同时也更快。对比Faster R-CNN，有2.3个点的优势，但是速度快很多。

### 总结

本文发现，类别不平衡是阻止一阶段网络超越二阶段网络的主要原因，由此我们提出了focal loss，在CE loss的基础上给出了调整参数，使训练的模型更多的被困难样本优化。本文的方法是简单且行之有效的，给出了RetinaNet这个一阶段的网络结构，同时多个实验结果也证明了在速度和精度上都是sota。

