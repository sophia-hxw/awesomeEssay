# 摘要
我们提出了 YOLO，一种新的物体检测方法。鉴于之前在目标检测上的工作是基于分类器的，相反，我们将目标检测框架化为“空间分离的边界框”和相关类概率的回归问题。单个神经网络在一次评估中直接从完整图像中预测边界框和类别概率，由于整个检测管道是一个单一的网络，因此可以直接在检测性能上进行端到端的优化。

我们的统一架构非常快，基础 YOLO 模型以每秒 45 帧的速度实时处理图像，较小版本 Fast YOLO 每秒处理 155 帧，同时准确率上是其他实时检测器的两倍 mAP。与最先进的检测系统相比，YOLO 会产生更多的定位错误，但不太可能在背景上预测误报。最后，YOLO 学习了非常通用的目标特征表示。当从自然图像泛化到艺术品等其他领域时，它优于其他检测方法，包括 DPM 和 R-CNN。

# 1，介绍
人类瞥一眼图像并立即知道图像中的对象是什么，它们在哪里，以及它们是如何交互的。 人类的视觉系统快速而准确，让我们能够在几乎没有意识的情况下执行复杂的任务，比如驾驶。 快速、准确的物体检测算法将允许计算机在没有专门传感器的情况下驾驶汽车，使辅助设备能够向人类用户传达实时场景信息，并释放通用、响应机器人系统的潜力。

当前的检测系统重新利用分类器来执行检测，为了检测一个对象，这些系统为该对象使用一个分类器，并在测试图像的不同位置和尺度上对其进行评估。 可变形部件模型 (DPM) 等系统使用滑动窗口方法，其中分类器在整个图像上的均匀间隔位置运行。

最近的方法如 R-CNN 使用区域提议方法首先在图像中生成潜在的边界框，然后在这些提议的框上运行分类器。分类后，后处理用于细化边界框，消除重复检测，并根据场景中的其他对象对框重新评分。这些复杂的管道速度缓慢且难以优化，因为每个单独的组件都必须单独训练。

我们将目标检测重新定义为单个回归问题，直接从图像像素到边界框坐标和类别概率。使用我们的系统，您只需查看图像一次 (YOLO) 即可预测存在哪些对象以及它们在哪里。

YOLO 非常简单：单个卷积网络同时预测多个边界框和这些框的类别概率，YOLO 在完整图像上训练并直接优化检测性能。与传统的对象检测方法相比，这种统一模型有几个优点。

首先，**YOLO 非常快**。由于我们将检测视为回归问题，因此我们不需要复杂的管道。我们只是在测试时在新图像上运行我们的神经网络来预测检测。我们的基础网络以每秒 45 帧的速度运行，在 Titan X GPU 上没有批处理，快速版本的运行速度超过 150 fps。这意味着我们可以以不到 25 毫秒的延迟实时处理流视频。此外，YOLO 的平均精度是其他实时系统平均精度的两倍以上。

其次，**YOLO 在进行预测时会对图像进行全局推理**。与基于滑动窗口和区域提议的技术不同，YOLO 在训练和测试期间看到整个图像，因此它隐式编码了关于类及其外观的上下文信息。 Fast R-CNN 是一种顶级检测方法，由于无法看到更大的上下文，因此将图像中的背景补丁误认为是对象。与 Fast R-CNN 相比，YOLO 的背景错误数量不到一半。

第三，**YOLO 学习目标的一般性特征表达**。当在自然图像上进行训练并在艺术品上进行测试时，YOLO 在很大程度上优于 DPM 和 R-CNN 等顶级检测方法。由于 YOLO 是高度可推广的，因此在应用于新领域或意外输入时不太可能崩溃。

YOLO 在准确性方面仍然落后于最先进的检测系统，虽然它可以快速识别图像中的物体，但它很难精确定位一些物体，尤其是小物体，我们在实验中进一步研究了这些权衡。

我们所有的训练和测试代码都是开源的。还可以下载各种预训练模型。

# 2，统一框架
我们将目标检测的独立组件统一到同一个神经网络中，使用来自整个图像的特征来预测每个边界框，同时能预测图像所有类别的所有边界框。这意味着网络需要对完整图像和图像中的所有对象进行全局推理，YOLO 设计支持端到端训练和实时速度，同时保持高平均精度。

我们的系统将输入图像划分为 S × S 网格。如果对象的中心落入网格单元中，则该网格单元负责检测该对象。

每个网格单元预测 B 个边界框和这些框的置信度分数，这些置信度分数反映了模型对单元格包含对象的信心程度，以及它认为盒子预测的准确度。形式上，我们将置信度定义为 $ Pr(Object) * IoU^{truth}_{pred} $ 。如果该单元格中不存在对象，则置信度应为零，否则，我们希望置信度得分等于预测框和真实标注之间的交集（IOU）。

每个边界框由 5 个预测组成：x、y、w、h 和置信度，(x, y) 坐标表示相对于网格单元边界的框中心，宽度和高度是相对于整个图像预测的。最后，置信度预测表示预测框和任何真实框之间的 IOU。

每个网格单元还预测 C 个条件类概率，Pr(Class i | Object)。这些概率以包含对象的网格单元为条件。我们只预测每个网格单元的一组类概率，而不管框 B 的数量。

在测试时，我们将条件类概率和单个框置信度预测相乘，

$$  Pr(Class_{i}|Object)*(Object)*IoU^{truth}_{pred} = Pr(Class_{i})*IoU^{truth}_{pred} $$

这为我们提供了每个框的特定类别的置信度分数，这些分数编码了该类别出现在框中的概率以及预测的框与对象的匹配程度。

为了在 PASCAL VOC 上评估 YOLO，我们使用 S = 7，B = 2。PASCAL VOC 有 20 个标记类别，因此 C = 20。我们的最终预测是一个 7 × 7 × 30 张量。

# 2.1 网络设计
我们将此模型实现为卷积神经网络，并在 PASCAL VOC 检测数据集上对其进行评估，网络的初始卷积层从图像中提取特征，而全连接层预测输出概率和坐标。

我们的网络架构受到用于图像分类的 GoogLeNet 模型的启发，有 24 个卷积层，后跟 2 个全连接层。 我们不使用 GoogLeNet 使用的初始模块，而是简单地使用 1 × 1 缩减层和 3 × 3 卷积层。

我们还训练了一个快速版本的 YOLO，旨在突破快速目标检测的界限。 Fast YOLO 使用具有较少卷积层（9 个而不是 24 个）和这些层中的过滤器较少的神经网络。 除了网络的大小之外，YOLO 和 Fast YOLO 的所有训练和测试参数都是相同的。

我们网络的最终输出是 7 × 7 × 30 的预测张量。





