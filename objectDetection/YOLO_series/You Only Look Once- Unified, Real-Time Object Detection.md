# 摘要
我们提出了 YOLO，一种新的物体检测方法。鉴于之前在目标检测上的工作是基于分类器的，相反，我们将目标检测框架化为“空间分离的边界框”和相关类概率的回归问题。单个神经网络在一次评估中直接从完整图像中预测边界框和类别概率，由于整个检测管道是一个单一的网络，因此可以直接在检测性能上进行端到端的优化。

我们的统一架构非常快，基础 YOLO 模型以每秒 45 帧的速度实时处理图像，较小版本 Fast YOLO 每秒处理 155 帧，同时准确率上是其他实时检测器的两倍 mAP。与最先进的检测系统相比，YOLO 会产生更多的定位错误，但不太可能在背景上预测误报。最后，YOLO 学习了非常通用的目标特征表示。当从自然图像泛化到艺术品等其他领域时，它优于其他检测方法，包括 DPM 和 R-CNN。

# 1，介绍
人类瞥一眼图像并立即知道图像中的对象是什么，它们在哪里，以及它们是如何交互的。 人类的视觉系统快速而准确，让我们能够在几乎没有意识的情况下执行复杂的任务，比如驾驶。 快速、准确的物体检测算法将允许计算机在没有专门传感器的情况下驾驶汽车，使辅助设备能够向人类用户传达实时场景信息，并释放通用、响应机器人系统的潜力。

当前的检测系统重新利用分类器来执行检测，为了检测一个对象，这些系统为该对象使用一个分类器，并在测试图像的不同位置和尺度上对其进行评估。 可变形部件模型 (DPM) 等系统使用滑动窗口方法，其中分类器在整个图像上的均匀间隔位置运行。

最近的方法如 R-CNN 使用区域提议方法首先在图像中生成潜在的边界框，然后在这些提议的框上运行分类器。分类后，后处理用于细化边界框，消除重复检测，并根据场景中的其他对象对框重新评分。这些复杂的管道速度缓慢且难以优化，因为每个单独的组件都必须单独训练。

我们将目标检测重新定义为单个回归问题，直接从图像像素到边界框坐标和类别概率。使用我们的系统，您只需查看图像一次 (YOLO) 即可预测存在哪些对象以及它们在哪里。

YOLO 非常简单：单个卷积网络同时预测多个边界框和这些框的类别概率，YOLO 在完整图像上训练并直接优化检测性能。与传统的对象检测方法相比，这种统一模型有几个优点。

首先，**YOLO 非常快**。由于我们将检测视为回归问题，因此我们不需要复杂的管道。我们只是在测试时在新图像上运行我们的神经网络来预测检测。我们的基础网络以每秒 45 帧的速度运行，在 Titan X GPU 上没有批处理，快速版本的运行速度超过 150 fps。这意味着我们可以以不到 25 毫秒的延迟实时处理流视频。此外，YOLO 的平均精度是其他实时系统平均精度的两倍以上。

其次，**YOLO 在进行预测时会对图像进行全局推理**。与基于滑动窗口和区域提议的技术不同，YOLO 在训练和测试期间看到整个图像，因此它隐式编码了关于类及其外观的上下文信息。 Fast R-CNN 是一种顶级检测方法，由于无法看到更大的上下文，因此将图像中的背景补丁误认为是对象。与 Fast R-CNN 相比，YOLO 的背景错误数量不到一半。

第三，**YOLO 学习目标的一般性特征表达**。当在自然图像上进行训练并在艺术品上进行测试时，YOLO 在很大程度上优于 DPM 和 R-CNN 等顶级检测方法。由于 YOLO 是高度可推广的，因此在应用于新领域或意外输入时不太可能崩溃。

YOLO 在准确性方面仍然落后于最先进的检测系统，虽然它可以快速识别图像中的物体，但它很难精确定位一些物体，尤其是小物体，我们在实验中进一步研究了这些权衡。

我们所有的训练和测试代码都是开源的。还可以下载各种预训练模型。

# 2，统一框架




