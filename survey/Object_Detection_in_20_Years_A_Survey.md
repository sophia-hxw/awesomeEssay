# 一，论文翻译

## 摘要
目标检测时计算机视觉中基础而有挑战性的方向，近些年得到了很大的发展，这段发展历程甚至可以作为计算机视觉历史中的里程碑。如果我们将深度学习对今天目标检测的促进看做是工业时代，那20年前则可以见证视觉方向的冷兵器时代。本文收录了400+文献来见证目标检测的发展，时间跨度可达四分之一个世纪(1990s-2019)，涵盖的主题也较多，包括**检测器发展的基石、检测数据集、评测指标、检测系统的基础构成部件、加速方法和近期sota的检测器。**同样，本文也设计了目标检测的常见应用方向，如**行人检测、人脸检测、文本检测等等**，会分析这些方向的技术进展和未来面临的挑战。

## 介绍

## 2，20年检测方法进化史

## 3，检测模型加速

### 3.4 网络剪枝和量化
剪枝和量化是CNN中常用的两个优化方式，前置对网络结构进行剪枝，后者对激活和权重的存储长度进行优化。

#### 3.4.1 网络剪枝
网络剪枝最早可以追溯到20世纪80年代，LeCun提出的"optimal brain damage"方法对多层感知机网络进行压缩，由于网络的loss函数是用二阶导数来近似的，所以就是用去掉不重要的权值。至今仍然在延续这个剪枝思想，即剪枝和训练整合且迭代多次，在每个训练阶段都可以去掉小部分不重要的权值。传统的剪枝方法就是简单的剪掉不重要的权值，这样会带来卷积核的稀疏连接问题，所以无法直接用来压缩CNN模型。一个简单的做法就是剪掉卷积核而不是独立的权值。

#### 3.4.2 网络量化
网络量化的最近进展集中在网络二值化，目标是将网络中的激活和权值二值化，这样就能将浮点预算转化为与、或、非的逻辑运算。网络二值化可显著加速运算和降低网络内存，所以可更简单的在移动设备上部署。一个二值化的可能实现思想就是使用最小二乘法将卷积近似为二值变量，更精确的近似也可用多个二值卷积的线性组合。此外，部分研究者正在探讨GPU上二值运算的加速库，可以获得更明显的加速效果。

#### 3.4.3 网络蒸馏
网络蒸馏是一个一般的大网络压缩到小网络的框架，近期这个优化的思想也被应用在目标检测模型上了。最直接的想法就是用大的教师模型来指导小的学生模型，让学生模型可以用于加速检测，另一个想法就是转化代表区域来减小老师网络和学生网络的距离。这类优化方法在保证检测准确率的同时获得了两倍的加速。

### 3.5 轻量级网络设计
近期加速CNN检测器的方法还有直接设计轻量级的网络，而不是使用现成的结构，研究者花了大量时间，为了找出在一定时间约束下可以获取更好准确率的模型配置参数。除了一些常用的规则，比如“更少的通道和更多的层”之外，近些几年还有几类其他的方法进入人们的视线：
- 卷积分解
- 组卷积
- 深度分离卷积
- bottle-neck设计
- NAS

#### 3.5.1 卷积分解
卷积分解是构建轻量级CNN中最简单和直接的策略，主要有两种分解方式。
- 在空间上，大卷积核拆分为一组小卷积核
  比如，一个7x7的卷积可以拆分成三个3x3的卷积来保证他们获得相同的感受野但是却可以更加高效。另一种方式是将一个kxk的卷积拆分成kx1和1xk的两个卷积，对一些大的卷积核，如15x15，会更加有效。这样的策略最近也已经在目标检测的任务中使用。

- 在通道上，将一组大的卷积拆分为两组小的卷积
  比如，能将c个通道的d个卷积核拆分成$d^{'}$个卷积核+一个非线性激活+d个卷积核($d^{'} < d$)。这样，计算复杂度可由原本的$O(dk^{2}c)$减少为$O(d^{'}k^{2}c)+O(d^{'}d)$。

#### 3.5.2 组卷积
组卷积是通过将特征通道拆分为几个不同的组来减少卷积层的参数，然后再每个组上分别执行卷积计算。比如，如果将卷积通道拆分为$m$个组，不修改其他任何参数的情况下，计算复杂度理论上可以降为$1/m$。

#### 3.5.3 深度分离卷积
深度分离卷积也是近期比较流行的构建轻量级网络的方法之一，可以看做组卷积的特例，此时的组数量等于通道的数量。

假设某个卷积层有d个卷积核，由c个通道的卷积图得到，每个卷积核大小为kxk，对每个深度卷积来说，每个kxkxc的卷积先被拆分为c组卷积，每组都使用kxkx1的卷积独立计算，之后使用1x1的卷积将输出的通道转化为d。使用深度分离卷积后的复杂度由$O(ck^{2}d)$为$O(ck^{2}+O(dc))$，这种思想也已经被应用到检测和分类模型。

#### 3.5.4 bottle-neck设计
CNN中的bottleneck层节点更少，可以减少维度的情况下学习到输入数据的有效编码，广泛应用在深度自动编码器中。近些年，bottleneck设计也被应用在轻量级网络的设计中。实现方法之一是压缩检测器的输入层来减少检测pipeline最开始的输入数量，另一种实现方法是压缩检测引擎的输出，使特征图更“瘦”，可以让网络之后的部分更高效。

#### 3.5.5 NAS
近期，也有较多研究成果在CNN的NAS中，取代了专家凭借经验和只是来设计网络。NAS被应用在大型图像分类、检测和分割任务中，同时也展示了在轻量级网络设计中有不俗的表现，可以在NAS搜索之前约束推理的准确率和计算的复杂度。

### 3.6 数值加速
在本节中，我们主要介绍物体检测中经常使用的四种重要的数值加速方法：
- 1）用积分图像加速；
- 2）在频域加速；
- 3）矢量量化；
- 4）降秩近似。

#### 3.6.1 积分图加速
积分图是图像处理中的重要方法，可用于加速图像区域的求和运算。积分图像的本质是信号处理中卷积的积分-微分可分性：
$$f(x)*g(x) = (\int f(x)dx)*(\frac{dg(x)}{dx})$$
其中$\frac{dg(x)}{dx}$是稀疏信号，然后卷积运算可以由等式的右边来进行加速。尽管VJ检测器是使用积分图进行加速的典型方法，再次之前，其实积分图就广泛用于CNN模型的加速并获得了10倍的加速结果。

除了上面的例子，积分图也可以用于目标检测中其他的普通特征加速，比如颜色直方图、梯度直方图等等。一个典型的方法是用HOG映射来计算HOG算法，不需要传统方法中的逐点计算，HOG积分映射计算图像的方向梯度。一个cell的直方图可以看做特定区域的梯度向量求和，而积分图可以加速这个运算，可以在常数计算开销下计算任意位置、大小方框的直方图。积分HOG映射在行人检测中已经开始使用，获得了几十倍的加速效果且不损失任何准确率。

之后在2009年，P.D提出了新型的图像特征，即积分通道特征(ICF)，可以看做图像积分特征的更一般的情况，被成功用在行人检测中，在实时应用中获得了sota的精度。

#### 3.6.2 频率域计算加速
卷积是目标检测中重要的数值计算，线性的检测器可以看做基于窗口的两个矩阵的额内积，第一个矩阵是特征层，另一个就是检测器的权重，这个过程可以用卷积实现。

卷积的加速方式有多重，傅里叶变化是实践中常用于大卷积核的加速。在频率域加速的原理就是信号处理中的卷积原理，也就是，在一定的条件下，两个卷积信号的傅里叶变换等于在傅里叶空间中的逐点乘积：
$$I * W = F^{-1}(F(I) \odot F(W))$$
其中，$*$便是卷积，$F^{-1}$是傅里叶逆变换，$F$是傅里叶变换，$\odot$是逐点乘积。上面式子可以用快速傅里叶变换和快速傅里叶逆变换来加速，这两个变换现在也经常用在CNN模型加速中了，可以在大小有序的情况下给检测器加速，参见HOG和DPM的相关原理。

#### 3.6.3 矢量量化
矢量量化是信号处理中的经典加速方法，常用在用小的数据集合来近似大组数据的分布，能用来做数据压缩，加速目标检测中的内积计算。比如，有了矢量量化，HOG直方图能分组且被量化为一个直方图向量集，然后在检测阶段，特征层和检测权重的内积可用简单查表操作来实现？由于没有浮点数的乘除法，DPM和SVM检测器可以在大小有序的条件下加速？

#### 3.6.4 降秩近似
深度网络中的全连接实际就是两个矩阵的乘法，当权值矩阵很大时，计算时很耗时间的。比如，Fast RCNN需要话将近一半的时间在全连接层，降秩近似是加速矩阵运算的方法之一。该方法主要是对权值矩阵做矩阵分解：
$$W \approx U\sum_{t}V$$

其中U是$uxt$阶且为W的左奇异矩阵，$\sum_{t}$是对角矩阵，V是$vxt$阶且为W的右奇异矩阵，这就是传说中的截断奇异值分解，将参数量从$uv$减少到$t(u+v)$，当然前提是t远小于$min(u,v)$，该方法在Fast RCNN中用于加速检测器，获得了两倍增速。

## 4，近三年的sota方法

## 5，重要的检测方法应用

## 6，未来研究的方向






