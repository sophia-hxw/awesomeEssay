# 一，论文翻译

## 摘要
目标检测时计算机视觉中基础而有挑战性的方向，近些年得到了很大的发展，这段发展历程甚至可以作为计算机视觉历史中的里程碑。如果我们将深度学习对今天目标检测的促进看做是工业时代，那20年前则可以见证视觉方向的冷兵器时代。本文收录了400+文献来见证目标检测的发展，时间跨度可达四分之一个世纪(1990s-2019)，涵盖的主题也较多，包括**检测器发展的基石、检测数据集、评测指标、检测系统的基础构成部件、加速方法和近期sota的检测器。**同样，本文也设计了目标检测的常见应用方向，如**行人检测、人脸检测、文本检测等等**，会分析这些方向的技术进展和未来面临的挑战。

## 介绍

## 2 20年检测方法进化史

## 3 检测模型加速

### 3.4 网络剪枝和量化
剪枝和量化是CNN中常用的两个优化方式，前置对网络结构进行剪枝，后者对激活和权重的存储长度进行优化。

#### 3.4.1 网络剪枝
网络剪枝最早可以追溯到20世纪80年代，LeCun提出的"optimal brain damage"方法对多层感知机网络进行压缩，由于网络的loss函数是用二阶导数来近似的，所以就是用去掉不重要的权值。至今仍然在延续这个剪枝思想，即剪枝和训练整合且迭代多次，在每个训练阶段都可以去掉小部分不重要的权值。传统的剪枝方法就是简单的剪掉不重要的权值，这样会带来卷积核的稀疏连接问题，所以无法直接用来压缩CNN模型。一个简单的做法就是剪掉卷积核而不是独立的权值。

#### 3.4.2 网络量化
网络量化的最近进展集中在网络二值化，目标是将网络中的激活和权值二值化，这样就能将浮点预算转化为与、或、非的逻辑运算。网络二值化可显著加速运算和降低网络内存，所以可更简单的在移动设备上部署。一个二值化的可能实现思想就是使用最小二乘法将卷积近似为二值变量，更精确的近似也可用多个二值卷积的线性组合。此外，部分研究者正在探讨GPU上二值运算的加速库，可以获得更明显的加速效果。

#### 3.4.3 网络蒸馏
网络蒸馏是一个一般的大网络压缩到小网络的框架，近期这个优化的思想也被应用在目标检测模型上了。最直接的想法就是用大的教师模型来指导小的学生模型，让学生模型可以用于加速检测，另一个想法就是转化代表区域来减小老师网络和学生网络的距离。这类优化方法在保证检测准确率的同时获得了两倍的加速。

### 3.5 轻量级网络设计
近期加速CNN检测器的方法还有直接设计轻量级的网络，而不是使用现成的结构，研究者花了大量时间，为了找出在一定时间约束下可以获取更好准确率的模型配置参数。除了一些常用的规则，比如“更少的通道和更多的层”之外，近些几年还有几类其他的方法进入人们的视线：
- 卷积分解
- 组卷积
- 深度分离卷积
- bottle-neck设计
- NAS

#### 3.5.1 卷积分解
卷积分解是构建轻量级CNN中最简单和直接的策略，主要有两种分解方式。
- 在空间上，大卷积核拆分为一组小卷积核
  比如，一个7x7的卷积可以拆分成三个3x3的卷积来保证他们获得相同的感受野但是却可以更加高效。另一种方式是将一个kxk的卷积拆分成kx1和1xk的两个卷积，对一些大的卷积核，如15x15，会更加有效。这样的策略最近也已经在目标检测的任务中使用。

- 在通道上，将一组大的卷积拆分为两组小的卷积
  比如，能将c个通道的d个卷积核拆分成$d^{'}$个卷积核+一个非线性激活+d个卷积核($d^{'} < d$)。这样，计算复杂度可由原本的$O(dk^{2}c)$减少为$O(d^{'}k^{2}c)+O(d^{'}d)$。

#### 3.5.2 组卷积
组卷积是通过将特征通道拆分为几个不同的组来减少卷积层的参数，然后再每个组上分别执行卷积计算。比如，如果将卷积通道拆分为$m$个组，不修改其他任何参数的情况下，计算复杂度理论上可以降为$1/m$。

#### 3.5.3 深度分离卷积
深度分离卷积也是近期比较流行的构建轻量级网络的方法之一，可以看做组卷积的特例，此时的组数量等于通道的数量。

假设某个卷积层有d个卷积核，由c个通道的卷积图得到，每个卷积核大小为kxk，对每个深度卷积来说，每个kxkxc的卷积先被拆分为c组卷积，每组都使用kxkx1的卷积独立计算，之后使用1x1的卷积将输出的通道转化为d。使用深度分离卷积后的复杂度由$O(ck^{2}d)$为$O(ck^{2}+O(dc))$，这种思想也已经被应用到检测和分类模型。

#### 3.5.4 bottle-neck设计
CNN中的bottleneck层节点更少，可以减少维度的情况下学习到输入数据的有效编码，广泛应用在深度自动编码器中。近些年，bottleneck设计也被应用在轻量级网络的设计中。实现方法之一是压缩检测器的输入层来减少检测pipeline最开始的输入数量，另一种实现方法是压缩检测引擎的输出，使特征图更“瘦”，可以让网络之后的部分更高效。

#### 3.5.5 NAS
近期，也有较多研究成果在CNN的NAS中，取代了专家凭借经验和只是来设计网络。NAS被应用在大型图像分类、检测和分割任务中，同时也展示了在轻量级网络设计中有不俗的表现，可以在NAS搜索之前约束推理的准确率和计算的复杂度。

### 3.6 数值加速
在本节中，我们主要介绍物体检测中经常使用的四种重要的数值加速方法：
- 1）用积分图像加速；
- 2）在频域加速；
- 3）矢量量化；
- 4）降秩近似。

#### 3.6.1 积分图加速
积分图是图像处理中的重要方法，可用于加速图像区域的求和运算。积分图像的本质是信号处理中卷积的积分-微分可分性：
$$f(x)*g(x) = (\int f(x)dx)*(\frac{dg(x)}{dx})$$
其中$\frac{dg(x)}{dx}$是稀疏信号，然后卷积运算可以由等式的右边来进行加速。尽管VJ检测器是使用积分图进行加速的典型方法，再次之前，其实积分图就广泛用于CNN模型的加速并获得了10倍的加速结果。

除了上面的例子，积分图也可以用于目标检测中其他的普通特征加速，比如颜色直方图、梯度直方图等等。一个典型的方法是用HOG映射来计算HOG算法，不需要传统方法中的逐点计算，HOG积分映射计算图像的方向梯度。一个cell的直方图可以看做特定区域的梯度向量求和，而积分图可以加速这个运算，可以在常数计算开销下计算任意位置、大小方框的直方图。积分HOG映射在行人检测中已经开始使用，获得了几十倍的加速效果且不损失任何准确率。

之后在2009年，P.D提出了新型的图像特征，即积分通道特征(ICF)，可以看做图像积分特征的更一般的情况，被成功用在行人检测中，在实时应用中获得了sota的精度。

#### 3.6.2 频率域计算加速
卷积是目标检测中重要的数值计算，线性的检测器可以看做基于窗口的两个矩阵的额内积，第一个矩阵是特征层，另一个就是检测器的权重，这个过程可以用卷积实现。

卷积的加速方式有多重，傅里叶变化是实践中常用于大卷积核的加速。在频率域加速的原理就是信号处理中的卷积原理，也就是，在一定的条件下，两个卷积信号的傅里叶变换等于在傅里叶空间中的逐点乘积：
$$I * W = F^{-1}(F(I) \odot F(W))$$
其中，$*$便是卷积，$F^{-1}$是傅里叶逆变换，$F$是傅里叶变换，$\odot$是逐点乘积。上面式子可以用快速傅里叶变换和快速傅里叶逆变换来加速，这两个变换现在也经常用在CNN模型加速中了，可以在大小有序的情况下给检测器加速，参见HOG和DPM的相关原理。

#### 3.6.3 矢量量化
矢量量化是信号处理中的经典加速方法，常用在用小的数据集合来近似大组数据的分布，能用来做数据压缩，加速目标检测中的内积计算。比如，有了矢量量化，HOG直方图能分组且被量化为一个直方图向量集，然后在检测阶段，特征层和检测权重的内积可用简单查表操作来实现？由于没有浮点数的乘除法，DPM和SVM检测器可以在大小有序的条件下加速？

#### 3.6.4 降秩近似
深度网络中的全连接实际就是两个矩阵的乘法，当权值矩阵很大时，计算时很耗时间的。比如，Fast RCNN需要话将近一半的时间在全连接层，降秩近似是加速矩阵运算的方法之一。该方法主要是对权值矩阵做矩阵分解：
$$W \approx U\sum_{t}V$$

其中U是$uxt$阶且为W的左奇异矩阵，$\sum_{t}$是对角矩阵，V是$vxt$阶且为W的右奇异矩阵，这就是传说中的截断奇异值分解，将参数量从$uv$减少到$t(u+v)$，当然前提是t远小于$min(u,v)$，该方法在Fast RCNN中用于加速检测器，获得了两倍增速。

## 4 近三年的sota方法

### 4.1 检测器中更好的引擎(backbone)
近来，深度CNN在很多视觉任务重都扮演了很核心的角色，因为检测器的性能很大程度受backbone提取的特征效果影响，这部分将会介绍几个DL中重要的backbone，详细了解可查阅参考文献。

- **AlexNet**
  8层，DL横扫CV界的排头兵，自2012年ImageNet LSVRC-2012上夺冠后声名大噪，截止到2019年，该论文的引用量已经3万多次。

- **VGG**
  自Oxford Visual Geometry Group在2014年提出，将模型的层从16增加到19，使用3x3等小卷积来替换5x5或者7x7的大卷积，在当时的ImageNet数据集上获得了sota。

- **GoogleNet**
  Google团队2014年提出的Inception类模型是个大家族，增加了CNN的宽度，且深度增加到了22层，Inception的主要贡献就是卷积分解和批量归一化。

- **ResNet**
  何凯明2015年提出了ResNet，是一个新的卷积网络框架，有152层，目的是用残差连接简化输入层之间的连接从而简化训练，获得了当年很多视觉竞赛，包括ImageNet检测，ImageNet定位，COCO检测和COCO分割。

- **DenseNet**
  2017年提出，ResNet的成功是提出了short cut连接，可以训练更深更精确的网络，相对的，本文作者提出了密集连接模块，让当前层与其他所有前向层都连接。

- **SENet**
  2018年提出，主要贡献是全局池化和学习基于通道的特征，SENet获得了ILSVRC2017分类赛的冠军。

- **检测器中的backbone**
  近三年，还有些其他的backbone用于检测任务，比如STDN, DSOD, TinyDSOD, Pelee等选择DenseNet作为backbone。Mask RCNN作为最好的实例分割模型，使用ResNet和ResNeXt作为backbone。除此之外，为了检测器的加速，深度分离卷积算子相关的Xception，也是Inception的加强版，常被用于MobileNet, LightHeadRCNN等的backbone。

### 4.2 检测器中更好的特征
特征提取的质量一直是目标检测的重要课题，近些年，许多研究者在提高backbone特征提取的质量方便做出了贡献，主要有两个大的思想：其一是特征融合；另一是高分辨率和大感受野。

#### 4.2.1 为什么特征融合重要？
不变性和等方差是图像特征提取的两个重要特征，分类任务更偏爱特征表示的不变性，因为他主要学习的是高层的分割信息；而定位任务则对等方差的特性更关注，因为他主要面临的是不同位置和多变的尺度。检测任务则包含上面两个特征，因为既要识别也要定位，所以检测器要同时学习不变性和等方差。

近三年来，特征融合在目标检测中得到了广泛的应用。由于 CNN 模型由一系列卷积层和池化层组成，因此更深层的特征将具有更强的不变性但更少的等方差。 虽然这可能对类别识别有益，但它在目标检测中存在定位精度低的问题。 相反，较浅层中的特征不利于学习语义，但它有助于对象定位，因为它包含更多关于边缘和轮廓的信息。 因此，CNN 模型中深度和浅层特征的集成有助于提高不变性和等方差性。

#### 4.2.2 特征融合的不同方式
此处介绍两种特征融合的方式，其一是处理流程，另一是基于处理元素。

- 处理流程
  最近在物体检测中的特征融合方法可以分为两类：1）自下而上的融合，2）自上而下的融合。 自下而上的融合通过跳跃连接将浅层特征前馈到更深的层，相比之下，自上而下的融合将较深层的特征反馈到较浅层 。 除了这些方法之外，最近还提出了更复杂的方法，例如，跨不同层编织特征。

  由于不同层的特征图在空间和通道维度方面可能具有不同的大小，因此可能需要适应特征图，例如通过调整通道数，对低分辨率图进行上采样 ，或将高分辨率地图下采样到适当的大小。 最简单的方法是使用最近或双线性插值。 此外，分数步幅卷积（又名转置卷积），是另一种最近流行的调整特征图大小和调整通道数量的方法。 使用分数步长卷积的优点是它可以学习一种适当的方法来自行执行上采样。
- 基于处理元素
  从局部的角度来看，特征融合可以被认为是不同特征图之间的元素操作。有三组方法：1) 逐元素求和，2) 逐元素积，和 3) 串联。
  
  按元素求和是执行特征融合的最简单方法。它已在许多最近的物体检测器中频繁使用。逐元素积与逐元素求和非常相似，唯一的区别是使用乘法而不是求和。逐元素积的一个优点是它可以用来抑制或突出特定区域内的特征，这可能进一步有利于小物体检测。特征连接是特征融合的另一种方式，它的优点是可以用来整合不同区域的上下文信息，缺点是增加了内存。

#### 4.2.3 学习具有大感受野的高分辨率特征
感受野和特征分辨率是基于 CNN 的检测器的两个重要特性，其中前者是指对输出的单个像素的计算有贡献的输入像素的空间范围，后者对应于down-sampling时输入和特征图之间的采样率。具有较大感受野的网络能够捕获更大范围的上下文信息，而具有较小感受野的网络可能更专注于局部细节。

正如我们之前提到的，特征分辨率越低，检测小物体就越困难。提高特征分辨率最直接的方法是去除池化层或降低卷积下采样率。但这会导致一个新的问题，由于输出步幅的减少，感受野会变得太小。换句话说，这会缩小检测器的“视线”，并可能导致某些大型物体的漏检。

同时增加感受野和特征分辨率的一种方法是引入扩张卷积，或者叫空洞卷积。扩张卷积最初是在语义分割任务中提出的。其主要思想是扩展卷积滤波器，使用稀疏参数。例如，膨胀率为 2 的 3x3 过滤器将具有与 5x5 内核相同的感受野，但只有 9 个参数。空洞卷积现在已广泛用于目标检测，并被证明可有效提高准确性，无需任何额外参数和计算成本。

### 4.3 滑动窗口之上的
尽管目标检测已经从手工特征发展到深度神经网络，但检测仍然遵循“特征图上的滑动窗口”的范式。 最近，在滑动窗口之外构建了一些检测器。

- 子区域搜索检测器
  子区域搜索提供了一种执行检测的新方法，实现方式之一是将检测视为从初始网格开始并最终收敛到所需的真实值框的路径规划过程；另一种实现是将检测视为迭代更新过程，以细化预测边界框的角点。
- 关键点定位检测器
  关键点定位是一项重要的计算机视觉任务，具有广泛的应用，例如面部表情识别、人体姿势识别等。因为图像中的任何对象都可以通过其左上角和下角唯一确定，因此检测任务可以等效地定义为成对关键点定位问题。这个想法的一个最近实现是预测角落的热图，这种方法的优点是可以在语义分割框架下实现，不需要设计多尺度的anchor box。

### 4.4 定位精度提高
为了提高定位的精度，有两种流行的做法，其一是bbox的细化；另一就是给定位问题设计更准确的loss函数。

#### 4.4.1 bbox的细化
提高定位精度最直观的方法是边界框细化，可以认为是对检测结果的后处理。尽管边界框回归已被集成到大多数现代对象检测器中，但仍有一些具有特殊尺度的对象无法被任何预定义的锚点很好地捕获。这将不可避免地导致对其位置的不准确预测。出于这个原因，最近引入了“迭代边界框细化”，通过将检测结果迭代地输入bbox回归器，直到预测收敛到正确的位置和大小。然而，也有研究人员声称这种方法并不能保证定位精度的单调性，换句话说，bbox回归如果多次应用可能会使定位退化。

#### 4.4.2 改进损失函数以实现准确定位
在大多数现代检测器中，目标定位被视为坐标回归问题。然而，这种范式有两个缺点。首先，回归损失函数与定位的最终评估不对应。例如，我们不能保证较低的回归误差总是会产生较高的IoU预测，尤其是当对象具有非常大的纵横比时。其次，传统的边界框回归方法不提供定位的置信度。当有多个bbox相互重叠时，这可能会导致非极大值抑制失败。

上述问题可以通过设计新的损失函数来缓解，最直观的设计是直接使用 IoU 作为定位损失函数，其他一些研究人员进一步提出了一种 IoU 引导的 NMS，以改善训练和检测阶段的定位。此外，一些研究人员还尝试在概率推理框架下改进定位，与之前直接预测框坐标的方法不同，该方法预测的是边界框位置的概率分布。

### 4.5 分割学习


### 4.6 旋转和尺度范围较大检测器的鲁棒性

### 4.7 从头训练

### 4.8 对抗训练

### 4.9 目标检测中的弱监督

## 5，重要的检测方法应用

### 5.1 行人检测

### 5.2 人脸检测

### 5.3 文本检测

### 5.4 交通标志和交通灯检测

### 5.5 远景目标检测

## 6，未来研究的方向

- **轻量级目标检测**
- **检测任务和AutoML**
- **检测任务和区域适应**
- **弱监督检测**
- **小目标检测**
- **视频目标检测**
- **检测与多源信息融合**






