# 一，论文翻译

## 摘要
目标检测时计算机视觉中基础而有挑战性的方向，近些年得到了很大的发展，这段发展历程甚至可以作为计算机视觉历史中的里程碑。如果我们将深度学习对今天目标检测的促进看做是工业时代，那20年前则可以见证视觉方向的冷兵器时代。本文收录了400+文献来见证目标检测的发展，时间跨度可达四分之一个世纪(1990s-2019)，涵盖的主题也较多，包括**检测器发展的基石、检测数据集、评测指标、检测系统的基础构成部件、加速方法和近期sota的检测器。**同样，本文也设计了目标检测的常见应用方向，如**行人检测、人脸检测、文本检测等等**，会分析这些方向的技术进展和未来面临的挑战。

## 介绍

## 2 20年检测方法进化史

## 3 检测模型加速

### 3.4 网络剪枝和量化
剪枝和量化是CNN中常用的两个优化方式，前置对网络结构进行剪枝，后者对激活和权重的存储长度进行优化。

#### 3.4.1 网络剪枝
网络剪枝最早可以追溯到20世纪80年代，LeCun提出的"optimal brain damage"方法对多层感知机网络进行压缩，由于网络的loss函数是用二阶导数来近似的，所以就是用去掉不重要的权值。至今仍然在延续这个剪枝思想，即剪枝和训练整合且迭代多次，在每个训练阶段都可以去掉小部分不重要的权值。传统的剪枝方法就是简单的剪掉不重要的权值，这样会带来卷积核的稀疏连接问题，所以无法直接用来压缩CNN模型。一个简单的做法就是剪掉卷积核而不是独立的权值。

#### 3.4.2 网络量化
网络量化的最近进展集中在网络二值化，目标是将网络中的激活和权值二值化，这样就能将浮点预算转化为与、或、非的逻辑运算。网络二值化可显著加速运算和降低网络内存，所以可更简单的在移动设备上部署。一个二值化的可能实现思想就是使用最小二乘法将卷积近似为二值变量，更精确的近似也可用多个二值卷积的线性组合。此外，部分研究者正在探讨GPU上二值运算的加速库，可以获得更明显的加速效果。

#### 3.4.3 网络蒸馏
网络蒸馏是一个一般的大网络压缩到小网络的框架，近期这个优化的思想也被应用在目标检测模型上了。最直接的想法就是用大的教师模型来指导小的学生模型，让学生模型可以用于加速检测，另一个想法就是转化代表区域来减小老师网络和学生网络的距离。这类优化方法在保证检测准确率的同时获得了两倍的加速。

### 3.5 轻量级网络设计
近期加速CNN检测器的方法还有直接设计轻量级的网络，而不是使用现成的结构，研究者花了大量时间，为了找出在一定时间约束下可以获取更好准确率的模型配置参数。除了一些常用的规则，比如“更少的通道和更多的层”之外，近些几年还有几类其他的方法进入人们的视线：
- 卷积分解
- 组卷积
- 深度分离卷积
- bottle-neck设计
- NAS

#### 3.5.1 卷积分解
卷积分解是构建轻量级CNN中最简单和直接的策略，主要有两种分解方式。
- 在空间上，大卷积核拆分为一组小卷积核
  比如，一个7x7的卷积可以拆分成三个3x3的卷积来保证他们获得相同的感受野但是却可以更加高效。另一种方式是将一个kxk的卷积拆分成kx1和1xk的两个卷积，对一些大的卷积核，如15x15，会更加有效。这样的策略最近也已经在目标检测的任务中使用。

- 在通道上，将一组大的卷积拆分为两组小的卷积
  比如，能将c个通道的d个卷积核拆分成$d^{'}$个卷积核+一个非线性激活+d个卷积核($d^{'} < d$)。这样，计算复杂度可由原本的$O(dk^{2}c)$减少为$O(d^{'}k^{2}c)+O(d^{'}d)$。

#### 3.5.2 组卷积
组卷积是通过将特征通道拆分为几个不同的组来减少卷积层的参数，然后再每个组上分别执行卷积计算。比如，如果将卷积通道拆分为$m$个组，不修改其他任何参数的情况下，计算复杂度理论上可以降为$1/m$。

#### 3.5.3 深度分离卷积
深度分离卷积也是近期比较流行的构建轻量级网络的方法之一，可以看做组卷积的特例，此时的组数量等于通道的数量。

假设某个卷积层有d个卷积核，由c个通道的卷积图得到，每个卷积核大小为kxk，对每个深度卷积来说，每个kxkxc的卷积先被拆分为c组卷积，每组都使用kxkx1的卷积独立计算，之后使用1x1的卷积将输出的通道转化为d。使用深度分离卷积后的复杂度由$O(ck^{2}d)$为$O(ck^{2}+O(dc))$，这种思想也已经被应用到检测和分类模型。

#### 3.5.4 bottle-neck设计
CNN中的bottleneck层节点更少，可以减少维度的情况下学习到输入数据的有效编码，广泛应用在深度自动编码器中。近些年，bottleneck设计也被应用在轻量级网络的设计中。实现方法之一是压缩检测器的输入层来减少检测pipeline最开始的输入数量，另一种实现方法是压缩检测引擎的输出，使特征图更“瘦”，可以让网络之后的部分更高效。

#### 3.5.5 NAS
近期，也有较多研究成果在CNN的NAS中，取代了专家凭借经验和只是来设计网络。NAS被应用在大型图像分类、检测和分割任务中，同时也展示了在轻量级网络设计中有不俗的表现，可以在NAS搜索之前约束推理的准确率和计算的复杂度。

### 3.6 数值加速
在本节中，我们主要介绍物体检测中经常使用的四种重要的数值加速方法：
- 1）用积分图像加速；
- 2）在频域加速；
- 3）矢量量化；
- 4）降秩近似。

#### 3.6.1 积分图加速
积分图是图像处理中的重要方法，可用于加速图像区域的求和运算。积分图像的本质是信号处理中卷积的积分-微分可分性：
$$f(x)*g(x) = (\int f(x)dx)*(\frac{dg(x)}{dx})$$
其中$\frac{dg(x)}{dx}$是稀疏信号，然后卷积运算可以由等式的右边来进行加速。尽管VJ检测器是使用积分图进行加速的典型方法，再次之前，其实积分图就广泛用于CNN模型的加速并获得了10倍的加速结果。

除了上面的例子，积分图也可以用于目标检测中其他的普通特征加速，比如颜色直方图、梯度直方图等等。一个典型的方法是用HOG映射来计算HOG算法，不需要传统方法中的逐点计算，HOG积分映射计算图像的方向梯度。一个cell的直方图可以看做特定区域的梯度向量求和，而积分图可以加速这个运算，可以在常数计算开销下计算任意位置、大小方框的直方图。积分HOG映射在行人检测中已经开始使用，获得了几十倍的加速效果且不损失任何准确率。

之后在2009年，P.D提出了新型的图像特征，即积分通道特征(ICF)，可以看做图像积分特征的更一般的情况，被成功用在行人检测中，在实时应用中获得了sota的精度。

#### 3.6.2 频率域计算加速
卷积是目标检测中重要的数值计算，线性的检测器可以看做基于窗口的两个矩阵的额内积，第一个矩阵是特征层，另一个就是检测器的权重，这个过程可以用卷积实现。

卷积的加速方式有多重，傅里叶变化是实践中常用于大卷积核的加速。在频率域加速的原理就是信号处理中的卷积原理，也就是，在一定的条件下，两个卷积信号的傅里叶变换等于在傅里叶空间中的逐点乘积：
$$I * W = F^{-1}(F(I) \odot F(W))$$
其中，$*$便是卷积，$F^{-1}$是傅里叶逆变换，$F$是傅里叶变换，$\odot$是逐点乘积。上面式子可以用快速傅里叶变换和快速傅里叶逆变换来加速，这两个变换现在也经常用在CNN模型加速中了，可以在大小有序的情况下给检测器加速，参见HOG和DPM的相关原理。

#### 3.6.3 矢量量化
矢量量化是信号处理中的经典加速方法，常用在用小的数据集合来近似大组数据的分布，能用来做数据压缩，加速目标检测中的内积计算。比如，有了矢量量化，HOG直方图能分组且被量化为一个直方图向量集，然后在检测阶段，特征层和检测权重的内积可用简单查表操作来实现？由于没有浮点数的乘除法，DPM和SVM检测器可以在大小有序的条件下加速？

#### 3.6.4 降秩近似
深度网络中的全连接实际就是两个矩阵的乘法，当权值矩阵很大时，计算时很耗时间的。比如，Fast RCNN需要话将近一半的时间在全连接层，降秩近似是加速矩阵运算的方法之一。该方法主要是对权值矩阵做矩阵分解：
$$W \approx U\sum_{t}V$$

其中U是$uxt$阶且为W的左奇异矩阵，$\sum_{t}$是对角矩阵，V是$vxt$阶且为W的右奇异矩阵，这就是传说中的截断奇异值分解，将参数量从$uv$减少到$t(u+v)$，当然前提是t远小于$min(u,v)$，该方法在Fast RCNN中用于加速检测器，获得了两倍增速。

## 4 近三年的sota方法

### 4.1 检测器中更好的引擎(backbone)
近来，深度CNN在很多视觉任务重都扮演了很核心的角色，因为检测器的性能很大程度受backbone提取的特征效果影响，这部分将会介绍几个DL中重要的backbone，详细了解可查阅参考文献。

- **AlexNet**
  8层，DL横扫CV界的排头兵，自2012年ImageNet LSVRC-2012上夺冠后声名大噪，截止到2019年，该论文的引用量已经3万多次。

- **VGG**
  自Oxford Visual Geometry Group在2014年提出，将模型的层从16增加到19，使用3x3等小卷积来替换5x5或者7x7的大卷积，在当时的ImageNet数据集上获得了sota。

- **GoogleNet**
  Google团队2014年提出的Inception类模型是个大家族，增加了CNN的宽度，且深度增加到了22层，Inception的主要贡献就是卷积分解和批量归一化。

- **ResNet**
  何凯明2015年提出了ResNet，是一个新的卷积网络框架，有152层，目的是用残差连接简化输入层之间的连接从而简化训练，获得了当年很多视觉竞赛，包括ImageNet检测，ImageNet定位，COCO检测和COCO分割。

- **DenseNet**
  2017年提出，ResNet的成功是提出了short cut连接，可以训练更深更精确的网络，相对的，本文作者提出了密集连接模块，让当前层与其他所有前向层都连接。

- **SENet**
  2018年提出，主要贡献是全局池化和学习基于通道的特征，SENet获得了ILSVRC2017分类赛的冠军。

- **检测器中的backbone**
  近三年，还有些其他的backbone用于检测任务，比如STDN, DSOD, TinyDSOD, Pelee等选择DenseNet作为backbone。Mask RCNN作为最好的实例分割模型，使用ResNet和ResNeXt作为backbone。除此之外，为了检测器的加速，深度分离卷积算子相关的Xception，也是Inception的加强版，常被用于MobileNet, LightHeadRCNN等的backbone。

### 4.2 检测器中更好的特征
特征提取的质量一直是目标检测的重要课题，近些年，许多研究者在提高backbone特征提取的质量方便做出了贡献，主要有两个大的思想：其一是特征融合；另一是高分辨率和大感受野。

#### 4.2.1 为什么特征融合重要？
不变性和等方差是图像特征提取的两个重要特征，分类任务更偏爱特征表示的不变性，因为他主要学习的是高层的分割信息；而定位任务则对等方差的特性更关注，因为他主要面临的是不同位置和多变的尺度。检测任务则包含上面两个特征，因为既要识别也要定位，所以检测器要同时学习不变性和等方差。

近三年来，特征融合在目标检测中得到了广泛的应用。由于 CNN 模型由一系列卷积层和池化层组成，因此更深层的特征将具有更强的不变性但更少的等方差。 虽然这可能对类别识别有益，但它在目标检测中存在定位精度低的问题。 相反，较浅层中的特征不利于学习语义，但它有助于对象定位，因为它包含更多关于边缘和轮廓的信息。 因此，CNN 模型中深度和浅层特征的集成有助于提高不变性和等方差性。

#### 4.2.2 特征融合的不同方式
此处介绍两种特征融合的方式，其一是处理流程，另一是基于处理元素。

- 处理流程
  最近在物体检测中的特征融合方法可以分为两类：1）自下而上的融合，2）自上而下的融合。 自下而上的融合通过跳跃连接将浅层特征前馈到更深的层，相比之下，自上而下的融合将较深层的特征反馈到较浅层 。 除了这些方法之外，最近还提出了更复杂的方法，例如，跨不同层编织特征。

  由于不同层的特征图在空间和通道维度方面可能具有不同的大小，因此可能需要适应特征图，例如通过调整通道数，对低分辨率图进行上采样 ，或将高分辨率地图下采样到适当的大小。 最简单的方法是使用最近或双线性插值。 此外，分数步幅卷积（又名转置卷积），是另一种最近流行的调整特征图大小和调整通道数量的方法。 使用分数步长卷积的优点是它可以学习一种适当的方法来自行执行上采样。
- 基于处理元素
  从局部的角度来看，特征融合可以被认为是不同特征图之间的元素操作。有三组方法：1) 逐元素求和，2) 逐元素积，和 3) 串联。
  
  按元素求和是执行特征融合的最简单方法。它已在许多最近的物体检测器中频繁使用。逐元素积与逐元素求和非常相似，唯一的区别是使用乘法而不是求和。逐元素积的一个优点是它可以用来抑制或突出特定区域内的特征，这可能进一步有利于小物体检测。特征连接是特征融合的另一种方式，它的优点是可以用来整合不同区域的上下文信息，缺点是增加了内存。

#### 4.2.3 学习具有大感受野的高分辨率特征
感受野和特征分辨率是基于 CNN 的检测器的两个重要特性，其中前者是指对输出的单个像素的计算有贡献的输入像素的空间范围，后者对应于down-sampling时输入和特征图之间的采样率。具有较大感受野的网络能够捕获更大范围的上下文信息，而具有较小感受野的网络可能更专注于局部细节。

正如我们之前提到的，特征分辨率越低，检测小物体就越困难。提高特征分辨率最直接的方法是去除池化层或降低卷积下采样率。但这会导致一个新的问题，由于输出步幅的减少，感受野会变得太小。换句话说，这会缩小检测器的“视线”，并可能导致某些大型物体的漏检。

同时增加感受野和特征分辨率的一种方法是引入扩张卷积，或者叫空洞卷积。扩张卷积最初是在语义分割任务中提出的。其主要思想是扩展卷积滤波器，使用稀疏参数。例如，膨胀率为 2 的 3x3 过滤器将具有与 5x5 内核相同的感受野，但只有 9 个参数。空洞卷积现在已广泛用于目标检测，并被证明可有效提高准确性，无需任何额外参数和计算成本。

### 4.3 滑动窗口之上的
尽管目标检测已经从手工特征发展到深度神经网络，但检测仍然遵循“特征图上的滑动窗口”的范式。 最近，在滑动窗口之外构建了一些检测器。

- 子区域搜索检测器
  子区域搜索提供了一种执行检测的新方法，实现方式之一是将检测视为从初始网格开始并最终收敛到所需的真实值框的路径规划过程；另一种实现是将检测视为迭代更新过程，以细化预测边界框的角点。
- 关键点定位检测器
  关键点定位是一项重要的计算机视觉任务，具有广泛的应用，例如面部表情识别、人体姿势识别等。因为图像中的任何对象都可以通过其左上角和下角唯一确定，因此检测任务可以等效地定义为成对关键点定位问题。这个想法的一个最近实现是预测角落的热图，这种方法的优点是可以在语义分割框架下实现，不需要设计多尺度的anchor box。

### 4.4 定位精度提高
为了提高定位的精度，有两种流行的做法，其一是bbox的细化；另一就是给定位问题设计更准确的loss函数。

#### 4.4.1 bbox的细化
提高定位精度最直观的方法是边界框细化，可以认为是对检测结果的后处理。尽管边界框回归已被集成到大多数现代对象检测器中，但仍有一些具有特殊尺度的对象无法被任何预定义的锚点很好地捕获。这将不可避免地导致对其位置的不准确预测。出于这个原因，最近引入了“迭代边界框细化”，通过将检测结果迭代地输入bbox回归器，直到预测收敛到正确的位置和大小。然而，也有研究人员声称这种方法并不能保证定位精度的单调性，换句话说，bbox回归如果多次应用可能会使定位退化。

#### 4.4.2 改进损失函数以实现准确定位
在大多数现代检测器中，目标定位被视为坐标回归问题。然而，这种范式有两个缺点。首先，回归损失函数与定位的最终评估不对应。例如，我们不能保证较低的回归误差总是会产生较高的IoU预测，尤其是当对象具有非常大的纵横比时。其次，传统的边界框回归方法不提供定位的置信度。当有多个bbox相互重叠时，这可能会导致非极大值抑制失败。

上述问题可以通过设计新的损失函数来缓解，最直观的设计是直接使用 IoU 作为定位损失函数，其他一些研究人员进一步提出了一种 IoU 引导的 NMS，以改善训练和检测阶段的定位。此外，一些研究人员还尝试在概率推理框架下改进定位，与之前直接预测框坐标的方法不同，该方法预测的是边界框位置的概率分布。

### 4.5 联合分割进行学习
检测和分割都是机器视觉中很重要的任务，最近有研究将二者整合来提高检测算法。

#### 4.5.1 为什么分割可以帮助提高检测？
主要有三个原因：

- 促进分类准确
  边缘和边界是构成人类视觉认知的基本元素。 在计算机视觉中，物体（例如汽车、人）和东西（例如天空、水、草）之间的区别在于，前者通常具有封闭且明确定义的边界，而后者则没有。 由于语义分割任务的特征很好地捕捉了对象的边界，因此分割可能有助于类别识别。

- 促进定位准确
  对象的真实边界框由其明确定义的边界确定。 对于一些具有特殊形状的物体（例如，想象一只尾巴很长的猫），很难预测高 IoU 位置。 由于对象边界可以在语义分割特征中很好地编码，因此通过分割进行学习将有助于准确的对象定位。

- 可嵌入为语境信息
  日常生活中的物体被不同的背景所包围，如天空、水、草等，所有这些元素构成了物体的语境。 整合语义分割的上下文将有助于对象检测，例如，飞机更可能出现在天空中而不是水上。

#### 4.5.2 分割任务如何促进检测任务？
通过分割改进对象检测有两种主要方法：1）使用丰富的特征进行学习；2）使用多任务损失函数进行学习。

- 1）使用丰富的特征进行学习
  最简单的方法是将分割网络视为固定特征提取器，并将其作为附加特征集成到检测框架中。 这种方式的优点是容易实现，缺点是分割网络可能带来额外的计算。

- 2）使用多任务损失函数进行学习
  另一种方法是在原始检测框架之上引入一个额外的分割分支，并使用多任务损失函数（分割损失 + 检测损失）来训练这个模型。 在大多数情况下，分割分支将在推理阶段被删除。 优点是检测速度不会受到影响，缺点是训练需要像素级的图像标注。 为此，一些研究人员遵循了“弱监督学习”的思想，他们不是基于像素级注释掩码进行训练，而是简单地基于边界框级别注释来训练分割分支。

### 4.6 旋转和尺度范围较大检测器的鲁棒性
目标旋转和尺度变化是对象检测中的重要挑战。 由于CNN学习到的特征对旋转和较大程度对尺度变化并不具有不变性，近年来很多人在这个问题上做了努力。

#### 4.6.1 旋转目标检测的鲁棒性
目标旋转在人脸检测、文本检测等检测任务中非常常见，这个问题最直接的解决方案是数据增强，以便任何方向的对象都可以被增强数据很好地覆盖。 另一种解决方案是为每个方向训练独立的检测器。 除了这些传统的方法，最近还有一些新的改进方法。

- 旋转不变损失函数
  使用旋转不变损失函数学习的想法可以追溯到 1990 年代，最近的一些工作引入了对原始检测损失函数的约束，以便使旋转对象的特征不变。

- 旋转校准
  另一种改进旋转不变检测的方法是对候选对象进行几何变换，这对于多级检测器尤其有用，其中早期阶段的相关性将有利于后续检测。 这个想法的代表是空间变压器网络（STN），STN 现在已用于旋转文本检测和旋转人脸检测。

- 旋转RoI池化
  在两阶段检测器中，特征池旨在通过首先将建议均匀划分为一组网格，然后连接网格特征，为具有任何位置和大小的对象建议提取固定长度的特征表示。 由于网格网格是在笛卡尔坐标系中执行的，因此特征对旋转变换不是不变的。 最近的改进是在极坐标中对网格进行网格划分，以便特征可以对旋转变化具有鲁棒性。

#### 4.6.2 大尺度范围的检测鲁棒性
最近在训练和检测阶段都对尺度鲁棒检测进行了改进。  

- 训练时的尺度自适应
  大多数现代检测器将输入图像重新缩放到固定大小，并在所有尺度上反向传播目标的损失。但是，这样做的一个缺点是会出现“尺度不平衡”的问题。在检测期间构建图像金字塔可以缓解这个问题，但不能从根本上缓解。最近的改进是图像金字塔的尺度归一化（SNIP），它在训练和检测阶段构建图像金字塔，并且只反向传播某些选定尺度的损失。一些研究人员进一步提出了一种更有效的训练策略，SNIPER，即将图像裁剪并重新缩放到一组子区域，以便从大批量训练中受益。

- 检测时的尺度自适应
  大多数现代检测器使用固定配置来检测不同尺寸的物体。例如，在典型的基于 CNN 的检测器中，我们需要仔细定义锚点的大小。 这样做的一个缺点是配置不能适应意外的规模变化。 为了改进小物体的检测，最近的一些检测器提出了一些“自适应放大”技术，以自适应地将小物体放大为“较大的物体”。 最近的另一个改进是学习预测图像中目标的尺度分布，然后根据分布自适应地重新缩放图像。
  
### 4.7 从头训练
大多数基于深度学习的检测器首先在大规模数据集上进行预训练，比如 ImageNet，然后在特定的检测任务上进行微调。人们一直认为预训练有助于提高泛化能力和训练速度，问题是，我们真的需要在 ImageNet 上预训练检测器吗？ 事实上，在目标检测中采用预训练网络时存在一些限制。 第一个限制是 ImageNet 分类和目标检测之间的差异，包括它们的损失函数和尺度/类别分布。 第二个限制是应用领域不匹配，由于 ImageNet 中的图像是 RGB 图像，而检测有时会应用于深度图像 (RGB-D) 或 3D 医学图像，因此预训练的知识不能很好地转移到这些检测任务中。

近年来，一些研究人员试图从头开始训练目标检测器。为了加速训练并提高稳定性，一些研究人员引入了密集连接和批量归一化来加速浅层的反向传播。某些研究人员通过探索相反的机制，进一步质疑了预训练的范式：他们报告了使用从随机初始化训练的标准模型在 COCO 数据集上进行目标检测的竞争结果，唯一的例外是增加训练迭代次数 随机初始化的模型会收敛。 即使仅使用 10% 的训练数据，随机初始化的训练也非常稳健，这表明 ImageNet 预训练可能会加速收敛，但不一定提供正则化或提高最终检测精度。


### 4.8 对抗训练
生成对抗网络 (GAN)，2014年提出，近年来备受关注。一个典型的 GAN 由两个神经网络组成：一个生成器网络和一个鉴别器网络，它们在一个极小极大优化框架中相互竞争。通常，生成器学习从潜在空间映射到感兴趣的特定数据分布，而鉴别器旨在区分真实数据分布中的实例和生成器生成的实例。 GAN 已被广泛用于许多计算机视觉任务，例如图像生成、图像风格转移和图像超分辨率。近两年，GAN 也被应用于物体检测，特别是用于改进小物体和被遮挡物体的检测。

GAN 已被用于通过缩小大小对象之间的特征表示来增强对小对象的检测 。为了改进对被遮挡物体的检测，最近的一个想法是通过使用对抗训练来生成遮挡掩码。对抗网络不是在像素空间中生成示例，而是直接修改特征以模拟遮挡。

除了这些工作，“对抗性攻击”旨在研究如何用对抗性示例攻击检测器，最近也引起了越来越多的关注。关于这个主题的研究对于自动驾驶尤其重要，但是在保证对抗性攻击的鲁棒性之前不能完全信任它。

### 4.9 目标检测中的弱监督
现代物体检测器的训练通常需要大量的人工标记数据，而标记过程耗时、昂贵且效率低下。弱监督目标检测 (WSOD) 旨在通过训练仅具有图像级注释而不是边界框的检测器来解决此问题。

最近，多实例学习已用于 WSOD。多实例学习是一组有监督的学习方法，模型不是使用一组单独标记的实例进行学习，而是接收一组标记的袋子，每个袋子包含许多实例。如果我们将一张图像中的候选对象视为一个袋子，并将图像级别的注释视为标签，那么 WSOD 可以被表述为一个多实例学习过程。

类激活映射是最近另一组用于 WSOD 的方法，对 CNN 可视化的研究表明，尽管没有对目标的位置进行监督，但 CNN 的卷积层充当目标检测器。类激活映射阐明了如何使 CNN 具有定位能力，尽管接受了图像级标签的训练。

除了上述方法之外，其他一些研究人员通过选择信息量最大的区域，然后使用图像级注释对这些区域进行训练，将 WSOD 视为提案排名过程。 WSOD 的另一种简单方法是屏蔽图像的不同部分。如果检测分数急剧下降，则目标将被高概率覆盖。此外，交互式注释在训练过程中加入人类反馈，以提高 WSOD。最近，生成对抗训练已用于 WSOD。

## 5，重要的检测方法应用
这部分会回顾近20年的重要检测应用，包括行人检测，人脸检测，文本检测，交通指示牌和交通信号灯检测，遥感目标检测等。

### 5.1 行人检测
行人检测作为重要的物体检测应用，在自动驾驶、视频监控、刑事侦查等诸多领域受到广泛关注。一些早期的行人检测方法，如HOG检测器、ICF检测器，在特征表示、分类器设计和检测加速方面为一般物体检测奠定了坚实的基础。 近年来，一些通用的物体检测算法，例如Faster RCNN，被引入到行人检测中，极大地推动了该领域的进步。

#### 5.1.1 难点和挑战
行人检测的挑战和困难可以总结如下：
- 小行人
  在 Caltech 数据集中，15% 的行人的高度小于 30 像素。
- 复杂背景
  街景图像中的一些背景在视觉外观上与行人非常相似。
- 密集和被遮挡的行人
  在 Caltech 数据集中，未被遮挡的行人占行人实例总数的 29%。
- 实时检测
  高清视频中的实时行人检测对于自动驾驶和视频监控等一些应用至关重要。

#### 5.1.2 论文简要回顾
行人检测有很长的研究历史，它的发展可以分为两个技术时期：1）传统的行人检测；2）基于深度学习的行人检测。 我们建议读者参阅综述。

- 传统行人检测方法
  由于计算资源的限制，Haar小波特征在早期的行人检测中得到了广泛的应用。为了改进对被遮挡行人的检测，当时一个流行的想法是“通过组件检测”，即将检测视为多个部分检测器的集合，这些检测器分别对不同的人体部位进行训练，例如头、腿和手臂。随着计算能力的提高，人们开始设计更复杂的检测模型，从2005年开始，基于梯度的表示和DPM成为行人检测的主流方法。 2009 年，通过使用积分图像加速，提出了一种有效且轻量级的特征表示：积分通道特征(ICF)，ICF 成为当时行人检测的新基准。除了特征表示外，还考虑了一些领域知识，例如外观恒定性和形状对称性和立体信息。

- 深度学习检测方法
  行人检测是第一个应用深度学习的计算机视觉任务之一。
   - 改进小型行人检测   
     尽管 Fast/Faster R-CNN 等深度学习对象检测器在一般对象检测方面表现出最先进的性能，但由于其分辨率低，它们在检测小型行人方面取得的成功有限。最近针对这个问题的一些解决方案包括特征融合、引入超高分辨率的手工特征以及在多个分辨率上集成检测结果。
   - 改进复杂背景的检测   
     最近的一些改进包括增强决策树的集成和语义分割（作为行人的上下文）。此外，还引入了“跨模态学习”的思想，通过使用 RGB 和红外图像来丰富复杂背景的特征。
   - 改进密集和被遮挡的行人检测   
     正如之前提到的，CNN 更深层的特征具有更丰富的语义，但对于检测密集物体无效。为此，一些研究人员通过考虑目标的吸引力和周围其他物体的排斥力设计了新的损失函数。目标遮挡是另一个通常伴随着密集行人出现的问题。部分检测器和注意力机制的集成是改进被遮挡行人检测的最常见方法。

### 5.2 人脸检测


### 5.3 文本检测

### 5.4 交通标志和交通灯检测

### 5.5 遥感目标检测

## 6，未来研究的方向

- **轻量级目标检测**
- **检测任务和AutoML**
- **检测任务和区域适应**
- **弱监督检测**
- **小目标检测**
- **视频目标检测**
- **检测与多源信息融合**






