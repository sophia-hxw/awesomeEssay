# 摘要
目标检测是计算机视觉中的一个基本视觉识别问题，在过去的几十年中得到了广泛的研究。视觉对象检测旨在在给定图像中找到具有精确定位的特定目标类的对象，并为每个对象实例分配一个相应的类标签。由于基于深度学习的图像分类的巨大成功，近年来使用深度学习的对象检测技术得到了积极的研究。在本文中，我们对深度学习视觉对象检测的最新进展进行了全面调查。通过回顾大量近期相关文献，我们系统地分析了现有的对象检测框架，并将调查分为三个主要部分：
- (i) 检测组件；
- (ii) 学习策略；
- (iii) 应用程序和基准测试。

在调查中，我们详细介绍了影响检测性能的各种因素，例如检测器架构、特征学习、建议框生成、采样策略等。最后，我们讨论了几个未来的方向，以促进和推动视觉对象检测的未来研究与深度学习。

关键词：对象检测，深度学习，深度卷积神经网络

# 1，介绍
在计算机视觉领域，有几个基本的视觉识别问题：图像分类、对象检测和实例分割和语义分割。特别是，图像分类旨在识别给定图像中对象的语义类别。对象检测不仅可以识别对象类别，还可以通过边界框预测每个对象的位置。语义分割旨在预测逐像素分类器，为每个像素分配一个特定的类别标签，从而提供对图像更丰富的理解。然而，与对象检测相反，语义分割不区分同一类别的多个对象。在对象检测和语义分割的交叉点上，提出了一种相对较新的设置，称为“实例分割”，用于识别不同的对象并为每个对象分配一个单独的分类像素级掩码。事实上，实例分割可以被视为对象检测的一种特殊设置，其中不需要通过边界框定位对象，而是需要像素级定位。在本次调查中，我们将注意力集中在回顾基于深度学习的对象检测方面的主要工作。一个好的检测算法应该对语义线索以及图像的空间信息有很强的理解。事实上，物体检测是许多计算机视觉应用的基本步骤，例如人脸识别，行人检测，视频分析和标志检测。

在早期，在深度学习时代之前，目标检测的流程分为三个步骤：i) 提议生成； ii) 特征向量提取；和 iii) 区域分类。在提议生成期间，目标是搜索图像中可能包含对象的位置。这些位置也称为感兴趣区域 (roi)。一个直观的想法是使用滑动窗口扫描整个图像。为了捕获有关对象的多尺度和不同纵横比的信息，将输入图像调整为不同的尺度，并使用多尺度窗口在这些图像中滑动。第二步，在图像的每个位置，从滑动窗口获得一个固定长度的特征向量，以捕获覆盖区域的判别语义信息。该特征向量通常由低级视觉描述符编码，例如 SIFT（尺度不变特征变换）、Haar、HOG（梯度直方图）或 SURF（加速鲁棒特征），这对尺度、光照和旋转方差表现出一定的鲁棒性。最后，在第三步中，学习区域分类器为覆盖区域分配分类标签。通常，这里使用支持向量机（SVM），因为它们在小规模训练数据上表现良好。此外，在区域分类步骤中使用了一些分类技术，如bagging、级联学习和 adaboost，从而进一步提高了检测精度。

大多数成功的传统目标检测方法都专注于精心设计特征描述符以获得感兴趣区域的嵌入。借助良好的特征表示和稳健的区域分类器，在 Pascal VOC 数据集（用于基准对象检测的公开可用数据集）上取得了令人印象深刻的结果。值得注意的是，基于可变形部件的机器 (DPM) 是一种突破性的检测算法，在 2007、2008 和 2009 年的 VOC 挑战赛中三度获胜。DPM 学习并集成具有可变形损失的多个部件模型，并使用用于判别训练的潜在 SVM。然而，在 2008 年到 2012 年期间，基于这些传统方法的 Pascal VOC 的进展变得渐进式，从构建复杂的集成系统中获得了微小的收益。这显示了这些传统探测器的局限性。最突出的是，这些限制包括：（i）在提案生成期间，生成了大量提案，其中许多是多余的；这导致分类期间出现大量误报。而且，窗口比例尺是手动设计的，启发式设计的，不能很好地匹配对象； (ii) 特征描述符是基于低级视觉线索手工制作的，这使得很难在复杂的上下文中捕获代表性语义信息。 (iii) 检测流程的每一步都是单独设计和优化的，因此无法获得整个系统的全局最优解。

在成功应用深度卷积神经网络（DCNN）进行图像分类之后，基于深度学习技术的目标检测也取得了显着进展。新的基于深度学习的算法以巨大的优势超越了传统的检测算法。深度卷积神经网络是一种用于计算层次特征的受生物学启发的结构。 Fukushima 提出的“neocognitron”是为图像分类构建这种分层和空间不变模型的早期尝试。然而，这种早期的尝试缺乏有效的监督学习优化技术。基于这个模型，Lecun 等人通过反向传播通过随机梯度下降 (SGD) 优化卷积神经网络，并在数字识别方面表现出有竞争力的性能。然而，在那之后，深度卷积神经网络并没有被深入探索，支持向量机变得更加突出。这是因为深度学习有一些局限性：(i) 缺乏大规模带标注的训练数据，导致过拟合； (ii) 有限的计算资源； (iii) 与 SVM 相比，理论支持较弱。 2009 年，贾等人收集了一个包含 1.2M 高分辨率图像的大规模注释图像数据集 ImageNet，使得用大规模训练数据训练深度模型成为可能。随着并行计算系统（如 GPU 集群）上计算资源的发展，2012 年 Krizhevsky 等人使用 ImageNet 数据集训练了一个大型深度卷积模型，与所有其他方法相比，在大规模视觉识别挑战（ILSVRC）上显示出显着改进。在成功应用 DCNN 进行分类后，深度学习技术迅速适应了其他视觉任务，并且与传统方法相比显示出有希望的结果。

与传统检测器中使用的手工描述符相比，深度卷积神经网络生成从原始像素到高级语义信息的分层特征表示，这些特征表示是从训练数据中自动学习的，并在复杂的上下文中显示出更具辨别力的表达能力。 此外，得益于强大的学习能力，深度卷积神经网络可以在更大的数据集下获得更好的特征表示，而传统的视觉描述符的学习能力是固定的，无法在更多数据可用时提高。 这些特性使得设计基于深度卷积神经网络的目标检测算法成为可能，该算法可以端到端的方式进行优化，具有更强大的特征表示能力。

目前，基于深度学习的对象检测框架主要可以分为两大类：(i) 两阶段检测器，例如基于区域的 CNN (R-CNN)及其变体，(ii) 一级检测器，例如 YOLO及其变体。两阶段检测器首先使用提议生成器生成一组稀疏提议并从每个提议中提取特征，然后是区域分类器预测提议区域的类别。一级检测器直接对特征图的每个位置上的对象进行分类预测，而无需级联区域分类步骤。两级检测器通常可以实现更好的检测性能并在公共基准上报告最先进的结果，而一级检测器的时间效率明显更高，并且对实时对象检测具有更大的适用性。
![obj_dec_milestones](assets/recent_advances.png)

本文是全面了解基于深度学习的对象检测算法。我们回顾了基于深度学习的对象检测的各种贡献，并将它们分为三组：检测组件、学习策略以及应用程序和基准。对于检测组件，我们首先介绍两个检测设置：边界框级别（bbox-level）和像素掩码级别（mask-level）定位。 Bbox 级算法需要通过矩形边界框来定位对象，而在掩码级算法中需要更精确的像素级掩码来分割对象。接下来，我们总结了两个检测家族的代表性框架：两阶段检测和一阶段检测。然后我们对每个检测组件进行了详细调查，包括主干架构、提议生成和特征学习。对于学习策略，由于训练检测器的难度，我们首先强调了检测学习策略的重要性，然后详细介绍了训练和测试阶段的优化技术。最后，我们回顾了一些基于现实世界物体检测的应用，包括人脸检测、行人检测、标志检测和视频分析。我们还讨论了这些检测任务的公开可用和常用的基准和评估指标。最后，我们展示了近年来在公共基准上进行通用检测的最新成果。
![obj_dec_components](assets/obj_dec_components.png)

我们希望本文能够为研究人员和从业人员提供及时的回顾，以进一步促进对检测系统的研究。 论文的其余部分组织如下：
- 在第 2 节中，我们给出了目标检测的标准问题设置；
- 第 3 节列出了检测器组件的详细信息；
- 第 4 节介绍了学习策略；
- 第 5 节和第 6 节提供了用于实际应用和基准的检测算法；
- 第 7 节列出了通用检测；
- 最后，我们在第 8 节总结和讨论未来的方向。

# 2，标准问题设置
在本节中，我们提出了基于深度学习的对象检测的正式问题设置。 对象检测涉及识别（例如，“对象分类”）和定位（例如，“位置回归”）任务。 对象检测器需要通过精确定位和对每个对象实例的正确分类标签预测，将某些目标类别的对象与图像中的背景区分开来，预测边界框或像素掩码以定位这些目标对象实例。

更一般的，若有N个带标注的图片${x_{1}, x_{2}...x_{N}}$，对第$i^{th}$张图片$x_{i}$，有$M_{i}$个物体属于C个类别，记作：
$$y_{i} = {(c^{i}_{1}, b^{i}_{1}),(c^{i}_{2}, b^{i}_{2})...(c^{i}_{i}, b^{i}_{i})}$$
其中$c^{i}_{j} \in C$代表类别，$b^{i}_{j}$代表$x_{i}$图片中第$j$个对象的空间坐标。检测器$f$可由$\theta$参数化，即对于$x_{i}$，推理结果与$y_{i}$的形式相同：
$$y^{i}_{pred} = {(c^{i}_{pred_{1}}, b^{i}_{pred_{1}}),(c^{i}_{pred_{2}}, b^{i}_{pred_{2}})...}$$
所以损失函数就是优化下列检测器：
$$l(x,\theta) = \frac{1}{N}\sum^{N}_{i=1}l(y^{i}_{pred}, x_{i}, y_{i};\theta)+\frac{\lambda}{2}||\theta ||^{2}_{2}$$
其中，第二项是带参数的归一化项，不同的loss函数有不同的侧重点，这块将在第4部分讲解。

在进行指标评价时，有一个变量经常用到，就是bbox和gt之间的IoU值，其定义如下：
$$IoU(b_{pred}, g_{gt}) =  \frac{Area(b_{pred}\cap b_{gt})}{Area(b_{pred}\cup b_{gt})}$$
推理中应用的IoU方式一般为：
$$Prediction = \begin{cases} Positive & c_{pred} = c_{gt} \, and\, IoU(b_{pred},b_{gt})>\omega \\ Negative & othersize \end{cases}$$

对于通用对象检测问题评估，使用 C 类上的平均精度 (mAP) 进行评估，并且在行人检测等实际场景中，使用不同的评估指标，这将在第 5 节中讨论。除了检测准确性，推理速度也是评估对象检测算法的重要指标。具体来说，如果我们希望检测视频流中的物体（实时检测），就必须有一个能够快速处理这些信息的检测器。 因此，检测器的效率也是根据每秒帧数 (FPS) 来评估的，即每秒可以处理多少图像。 通常可以达到 20 FPS 推理速度的检测器被认为是实时检测器。

# 3，检测组件
在本节中，我们将介绍对象检测的不同组件。 首先是关于对象检测范式的选择。 我们首先介绍两种检测设置的概念：bbox 级和掩码级算法。 然后，我们介绍两种主要的物体检测范式：两级检测器和一级检测器。 在这些范式下，检测器可以使用各种深度学习主干架构、提议生成器和特征表示模块。

## 3.1 检测设置
对象检测有两种设置：
- i）普通对象检测（bbox 级定位）
- ii）实例分割（像素级或掩码级定位）。 

Vanilla 对象检测已得到更广泛的研究，被认为是传统的检测设置，其目标是通过矩形边界框定位对象。在vanilla 目标检测算法中，只需要bbox标注框，并且在评估中，计算预测的bbox与gt之间的IoU来衡量性能。实例分割是一个相对较新的设置，基于传统的检测设置。实例分割需要通过像素级掩码而不是粗略的矩形边界框来分割每个对象。由于更精确的像素级预测，实例分割对空间错位更敏感，因此对处理空间信息的要求更高。实例分割的评估指标几乎与 bbox 级检测相同，除了 IoU 计算是在掩码预测上执行的。虽然这两个检测设置略有不同，但后面介绍的主要组件大多可以由这两个设置共享。

## 3.2 检测算法路线
当前最先进的深度学习目标检测器主要可以分为两大类：两级检测器和一级检测器。对于两阶段检测器，在第一阶段，生成一个稀疏的提议集；在第二阶段，生成的提议的特征向量由深度卷积神经网络编码，然后进行对象类别预测。一级检测器没有单独的提议生成阶段（或学习提议生成）。他们通常将图像上的所有位置都视为潜在对象，并尝试将每个感兴趣的区域分类为背景或目标对象。两阶段检测器经常在许多公共基准数据集上报告最先进的结果。然而，它们通常在较低的推理速度方面存在不足。一级检测器在实时物体检测应用中速度更快，更受欢迎，但与二级检测器相比，其性能相对较差。

### 3.2.1 二阶段检测算法
两阶段检测器将检测任务分为两个阶段：（i）提议生成； (ii) 对这些提议进行预测。 在提议生成阶段，检测器将尝试识别图像中可能是对象的区域。 这个想法是提出具有高召回率的区域，使得图像中的所有对象至少属于这些提议区域中的一个。 在第二阶段，基于深度学习的模型用于使用正确的分类标签对这些建议进行分类。 该区域可以是背景，也可以是来自预定义类标签之一的对象。 此外，该模型可以改进提案生成器建议的原始定位。 接下来，我们回顾了两阶段检测器中一些最有影响力的工作。

**R-CNN** 是 Girshick 等人提出的开创性的两阶段目标检测器。在 2014 年。 与之前基于传统检测框架 SegDPM 的最先进方法相比，Pascal VOC2010 上的 mAP 为 40.4%，R-CNN 显着提高了检测性能并获得了 53.7% 的 mAP。R-CNN 的管道可以分为三个部分：i) 提议生成，ii) 特征提取和 iii) 区域分类。对于每张图像，R-CNN 通过选择性搜索生成一组稀疏的提议（大约 2,000 个提议），旨在拒绝可以轻松识别为背景区域的区域。然后，每个提议被裁剪并调整为固定大小的区域，并由深度卷积神经网络编码为（例如 4,096 维）特征向量，然后是一对多 SVM 分类器。最后，使用提取的特征作为输入来学习边界框回归器，以使原始提议紧密地绑定对象。与传统的手工特征描述符相比，深度神经网络生成分层特征并捕获不同层的不同尺度信息，最终产生用于分类的鲁棒性和判别性特征。利用迁移学习的力量，R-CNN 采用在 ImageNet 上预训练的卷积网络的权重。为检测任务重新初始化最后一个全连接层（FC 层）。然后在预训练模型上对整个检测器进行微调。这种来自 Imagenet 数据集的知识转移提供了显着的性能提升。此外，R-CNN 在训练前拒绝了大量的简单否定，这有助于提高学习速度并减少误报。

然而，R-CNN 面临一些严重的缺点：i）每个提议的特征都是由深度卷积网络单独提取的（即计算不共享），这导致了大量重复的计算。 因此，R-CNN 的训练和测试非常耗时； ii）R-CNN的三个步骤（提议生成、特征提取和区域分类）是独立的组成部分，整个检测框架不能以端到端的方式进行优化，难以获得全局最优解 ; iii) 选择性搜索依赖于低级别的视觉线索，因此难以在复杂的上下文中生成高质量的建议。 此外，它无法享受到的好处
GPU加速。

受到空间金字塔匹配（SPM）思想的启发，何凯明等人提出了 SPP-net 来加速 R-CNN 并学习更多的判别特征。 SPP-net 不是单独裁剪提议区域并输入 CNN 模型，而是使用深度卷积网络从整个图像计算特征图，并通过空间金字塔池化 (SPP) 层在特征图上提取固定长度的特征向量. SPP将特征图划分成一个N×N的网格，对于N的多个值（从而允许在不同尺度上获取信息），并对网格的每个单元进行池化，给出一个特征向量。从每个 N × N 网格获得的特征向量被连接起来以给出该区域的表示。提取的特征被送入区域 SVM 分类器和边界框回归器。与 RCNN 相比，SPP 层还可以在不同尺度和纵横比的图像/区域上工作，而无需调整它们的大小。因此，它不会受到信息丢失和不需要的几何失真的影响。

与 R-CNN 相比，SPP-net 取得了更好的结果，并且具有明显更快的推理速度。然而，SPP-net 的训练仍然是多阶段的，因此无法进行端到端的优化（并且需要额外的缓存来存储提取的特征）。此外，SPP 层没有将梯度反向传播到卷积核，因此 SPP 层之前的所有参数都被冻结。这极大地限制了深度骨干架构的学习能力。吉尔希克等人提出了 Fast R-CNN，这是一种多任务学习检测器，解决了 SPP-net 的这两个局限性。 Fast R-CNN（如 SPP-Net）也为整个图像计算了一个特征图，并在特征图上提取了固定长度的区域特征。与 SPP-net 不同，Fast R-CNN 使用 ROI Pooling 层来提取区域特征。 ROI 池化层是 SPP 的一个特例，它只需要一个尺度（即 N × N 网格只有一个 N 值）将提议划分为固定数量的分区，并将误差信号反向传播到卷积核。在特征提取之后，特征向量被输入到两个兄弟输出层之前的一系列全连接层：分类层（cls）和回归层（reg）。分类层负责生成 C+1 类（C 类加一个背景类）的 softmax 概率，而回归层编码 4 个实值参数以细化边界框。在 Fast RCNN 中，特征提取、区域分类和边界框回归步骤都可以端到端优化，无需额外的缓存空间来存储特征（与 SPP Net 不同）。 Fast R-CNN 实现了比 R-CNN 和 SPP-net 更好的检测精度，并且具有更好的训练和推理速度。

尽管在学习检测器方面取得了进展，但提案生成步骤仍然依赖于传统方法，如选择性搜索或边缘框，这些方法基于低级视觉线索，无法在数据驱动的方式。为了解决这个问题，开发了 Faster R-CNN，它依赖于一种新颖的提议生成器：区域提议网络（RPN）。这个提议生成器可以通过监督学习方法来学习。 RPN 是一个完全卷积的网络，它采用任意大小的图像并在特征图的每个位置生成一组对象提议。网络使用 n × n 滑动窗口在特征图上滑动，并为每个位置生成一个特征向量。然后将特征向量送入两个兄弟输出分支，对象分类层（对提议是否为对象进行分类）和边界框回归层。然后将这些结果输入到最后一层，用于实际的对象分类和边界框定位。 RPN 可以插入到 Fast R-CNN 中，因此整个框架可以在训练数据上以端到端的方式进行优化。通过这种方式，RPN 能够以数据驱动的方式生成提议，并且还能够享受深层主干网络的判别能力。 Faster R-CNN 能够在 GPU 上以 5FPS 进行预测，并在许多公共基准数据集上取得了最先进的结果，例如 Pascal VOC 2007、2012 和 MSCOCO。目前，有大量基于 Faster R-CNN 的检测器变体，用于不同的用途。

Faster R-CNN 计算输入图像的特征图并提取特征图上的区域特征，跨不同区域共享特征提取计算。然而，计算并未在区域分类步骤中共享，其中每个特征向量仍然需要分别通过一系列 FC 层。这种额外的计算可能非常大，因为每个图像可能有数百个提议。简单地去除全连接层会导致检测性能的急剧下降，因为深度网络会减少建议的空间信息。戴等人提出了基于区域的全卷积网络（R-FCN），它在区域分类步骤中分担了计算成本。 R-FCN生成一个Position Sensitive Score Map，对不同类别的相对位置信息进行编码，并使用Position Sensitive ROI Pooling layer（PSROI Pooling）通过对目标区域的每个相对位置进行编码来提取空间感知区域特征。提取的特征向量保留了空间信息，因此与没有区域全连接层操作的 Faster R-CNN 相比，检测器取得了有竞争力的结果。

Faster R-CNN 的另一个问题是它使用单个深层特征图来进行最终预测。这使得检测不同尺度的物体变得困难。特别是，很难检测到小物体。在 DCNN 特征表示中，深层特征语义强但空间弱，而浅层特征语义弱但空间强。林等人利用这一特性并提出了特征金字塔网络（FPN），该网络将深层特征与浅层特征相结合，以在不同尺度的特征图中实现对象检测。主要思想是通过来自更深层的丰富语义信息来加强空间强的浅层特征。 FPN 在检测多尺度对象方面取得了重大进展，并已广泛应用于许多其他领域，如视频检测和人体姿势识别。

大多数实例分割算法都是从普通对象检测算法扩展而来的。早期的方法通常生成分段建议，然后是用于分段分类的 Fast RCNN。后来，戴等人提出了一种名为“MNC”的多阶段算法，它将整个检测框架分为多个阶段，并从学习到的边界框建议中预测分割掩码，然后由区域分类器进行分类。这些早期的作品在多个阶段进行了 bbox 和 mask 预测。为了使整个过程更加灵活，He等人提出了 Mask R-CNN，它根据建议并行预测边界框和分割掩码，并报告了最先进的结果。 Huang等人基于Mask R-CNN提出了一个掩码质量感知框架，称为掩码评分 R-CNN，它学习了预测掩码的质量并校准了掩码质量和掩码置信度分数之间的错位。
![two_stages_obj_dec](assets/two_stages.png)

### 3.2.2 一阶段算法
与两阶段检测算法不同，两阶段检测算法将检测管道分为两部分：提议生成和区域分类；一级检测器没有单独的提案生成阶段（或学习提案生成）。他们通常将图像上的所有位置都视为潜在对象，并尝试将每个感兴趣的区域分类为背景或目标对象。

早期成功的基于深度学习的单级检测器之一是由 Sermanet 等人开发的，命名为 Over-Feat。 OverFeat 通过将 DCNN 分类器转换为完全卷积的对象检测器来执行对象检测。对象检测可以被视为“多区域分类”问题，因此 OverFeat 通过将最后的 FC 层视为 1x1 卷积层以允许任意输入将原始分类器扩展为检测器。分类网络输出对输入的每个区域的预测网格，以指示对象的存在。在识别对象后，学习边界框回归器以基于分类器的相同 DCNN 特征来细化预测区域。为了检测多尺度对象，将输入图像调整为多个尺度，然后输入网络。最后，将所有尺度的预测合并在一起。通过使用卷积层共享重叠区域的计算，与 RCNN 相比，OverFeat 显示出显着的速度强度，并且只需要通过网络向前传递一次。然而，分类器和回归器的训练是分开的，没有联合优化。

后来，雷德蒙等人开发了一种名为 YOLO（你只看一次）的实时检测器。 YOLO 将对象检测视为回归问题，并将整个图像在空间上划分为固定数量的网格单元（例如使用 7 × 7 网格）。每个单元格都被认为是检测压力的提议
一个或多个对象。在最初的实现中，每个单元格都被认为包含（最多）两个对象的中心。对于每个单元格，进行了包含以下信息的预测：该位置是否有对象、边界框坐标和大小（宽度和高度）以及对象的类别。整个框架是一个单一的网络，它省略了可以以端到端方式优化的提案生成步骤。基于精心设计的轻量级架构，YOLO 可以在 45 FPS 时进行预测，并通过更简化的主干达到 155 FPS。然而，YOLO 面临一些挑战：i）它在给定位置最多只能检测两个物体，这使得检测小物体和拥挤的物体变得困难。 ii) 仅使用最后一个特征图进行预测，不适合在多尺度和长宽比下预测对象。

2016 年，刘等人提出了另一种单级检测器 Single-Shot Mulibox Detector (SSD)，它解决了 YOLO 的局限性。 SSD 也将图像划分为网格单元，但在每个网格单元中，会生成一组具有多个尺度和纵横比的锚点来离散边界框的输出空间（与 YOLO 中采用的固定网格单元进行预测不同）。每个锚点都通过学习的 4 值偏移量进行细化回归器分配，并由分类器分配 (C+1) 分类概率。此外，SSD 在多个特征图上预测对象，每个特征图负责根据其感受野检测一定尺度的对象。为了检测大型物体并增加感受野，在原始主干架构中添加了几个额外的卷积特征图。通过端到端的训练方案，对所有预测图的定位损失和分类损失的加权总和对整个网络进行了优化。最终预测是通过合并来自不同特征图的所有检测结果进行的。为了避免大量的负提议主导训练梯度，使用硬负挖掘来训练检测器。还应用了密集的数据增强来提高检测精度。 SSD 实现了与 Faster R-CNN 相当的检测精度，但具有进行实时推理的能力。

如果没有提议生成来过滤简单的负样本，前景和背景之间的类别不平衡是单级检测器中的一个严重问题。 林等人提出了一种单级检测器 RetinaNet，它以更灵活的方式解决了类不平衡问题。 RetinaNet 使用焦点损失来抑制简单的负样本的梯度，而不是简单地丢弃它们。 此外，他们使用特征金字塔网络来检测不同级别特征图的多尺度对象。 他们提出的焦点损失大大优于朴素的硬负挖掘策略。

雷德蒙等人提出了一个改进的 YOLO 版本，YOLOv2，它显着提高了检测性能，但仍然保持了实时推理速度。 YOLOv2 采用了更强大的深度卷积骨干架构，该架构在来自 ImageNet（从 224 × 224 到 448 × 448）的更高分辨率图像上进行了预训练，因此学习的权重对捕获细粒度信息更加敏感。 此外，受 SSD 中使用的锚点策略的启发，YOLOv2 通过从训练数据（而不是手动设置）中的 k-means 聚类定义了更好的锚点先验。 这有助于减少本地化的优化难度。 最后结合 Batch Normalization 层和多尺度训练技术，YOLOv2 达到了当时最先进的检测结果。

之前的方法需要手动设计锚框来训练检测器。 后来开发了一系列无锚对象检测器，其目标是预测边界框的关键点，而不是尝试将对象拟合到锚点。 Law 和 Deng 提出了一种新的无锚框架 CornerNet，它将对象检测为一对角。 在特征图的每个位置，预测类热图、对嵌入和角偏移。 类热图计算成为角的概率，角偏移用于回归角位置。 并且成对嵌入用于将属于相同对象的一对角进行分组。 在不依赖手动设计的锚点匹配对象的情况下，CornerNet 在 MSCOCO 数据集上获得了显着的改进。 后来还有其他几种基于关键点检测的单级检测器变体。

![one_stages](assets/one_stages.png)

## 3.3 backbone结构
R-CNN 表明，采用在大规模图像分类问题上预训练的模型的卷积权重可以为训练检测器提供更丰富的语义信息并提高检测性能。 在后来的几年中，这种方法已成为大多数对象检测器的默认策略。 在本节中，我们将首先简要介绍深度卷积神经网络的基本概念，然后回顾一些广泛用于检测的架构。

### 3.3.1 CNN的基本模块
深度卷积神经网络 (DCNN) 是典型的深度神经网络，已被证明在视觉理解方面极为有效。 深度卷积神经网络通常由一系列卷积层、池化层、非线性激活层和全连接层（FC 层）组成。 卷积层采用图像输入并通过 n×n 个内核对其进行卷积以生成特征图。

生成的特征图可以看作是多通道图像，每个通道代表图像的不同信息。 特征图中的每个像素（称为神经元）都连接到前一个图中的一小部分相邻神经元，称为感受野。 生成特征图后，应用非线性激活层。 池化层用于汇总感受野内的信号，扩大感受野并降低计算成本。

通过一系列卷积层、池化层和非线性激活层的组合，构建了深度卷积神经网络。 整个网络可以通过基于梯度的优化方法（随机梯度下降、Adam 等）通过定义的损失函数进行优化。 一个典型的卷积神经网络是 AlexNet，它包含五个卷积层、三个最大池化层和三个全连接层。 每个卷积层后跟一个 ReLU非线性激活层。

### 3.3.2 目标检测的CNN backbone
在本节中，我们将回顾一些广泛用于具有最先进结果的目标检测任务的架构，例如 VGG16、ResNet、ResNeXt和沙漏。

VGG16 是基于 AlexNet 开发的。 VGG16由五组卷积层和三个FC层组成。前两组有两个卷积层，后三组有三个卷积层。在每个组之间，应用一个最大池化层来减少空间维度。 VGG16 表明，通过堆叠卷积层来增加网络深度可以提高模型的表达能力，并带来更好的性能。然而，通过简单地堆叠卷积层将模型深度增加到 20 层导致了 SGD 的优化挑战。性能显着下降，甚至在训练阶段也不如较浅的模型。基于这一观察，He 等人提出了 ResNet，它通过引入快捷连接来降低优化难度。在这里，一层可以跳过非线性变换并直接将值按原样传递给下一层（从而给我们一个隐式身份层）。给出如下：
$$x_{l+1} = x_{l} + f_{l+1}(x_{l},\theta )$$

快捷连接创建了一条高速公路，将梯度从深层直接传播到浅层单元，从而显着降低了训练难度。通过残差块有效地训练网络，模型深度可以增加（例如从 16 到 152），使我们能够训练非常高容量的模型。后来，Ta等人提出了一种 ResNet 的预激活变体，名为 ResNet-v2。他们的实验表明，Batch Normalization 的适当排序可以进一步比原始 ResNet 表现得更好。这种对 ResNet 的简单但有效的修改使得成功训练超过 1000 层的网络成为可能，并且由于深度的增加，性能仍然得到提高。黄等人认为虽然 ResNet 通过快捷连接降低了训练难度，但它并没有充分利用前一层的特征。浅层中的原始特征在逐元素操作中丢失，因此无法在以后直接使用。他们提出了 DenseNet，它保留了浅层特征，并通过将输入与残差输出连接而不是逐元素添加来改进信息流：
$$x_{l+1} = x_{l} \circ f_{l+1}(x_{l},\theta )$$

其中$\circ$表示串联。 陈等争辩说在 DenseNet 中，来自低层被复制并产生高计算成本。综合了 ResNet 和 DenseNet 的优点，它们提出一种划分$x_{l}$通道的双路径网络（DPN）分为两部分： $ x^{d}_{l} $ 和 $ x^{r}_{l} $ 。 $ x^{d}_{l} $ 用于密集连接计算 和 $ x^{r}_{l} $ 用于按元素求和，具有未共享的残差学习分支 $ f^{d}_{l+1} $ 和 $f^{r}_{l+1} $ 。 最后的结果是两个分支的连接输出：

$$ x_{l+1}  = (x^{r}_{l} + f^{r}_{l+1}(x^{r}_{l}, \theta^{r}))\circ(x^{d}_{l}\circ f^{d}_{l+1}(x^{d}_{l},\theta^{d})) $$

Xie 等人基于 ResNet提出了 ResNeXt，它大大降低了计算和内存成本，同时保持了相当的分类精度。 ResNeXt 采用组卷积层，稀疏连接特征图通道以降低计算成本。 通过增加组数以保持计算成本与原始 ResNet 一致，ResNeXt 从训练数据中捕获更丰富的语义特征表示，从而提高主干精度。 后来，霍华德等人将坐标设置为等于每个特征图的通道数并开发了 MobileNet。 MobileNet 显着降低了计算成本和参数数量，而分类精度没有显着损失。 该模型专为在移动平台上使用而设计。

除了增加模型深度之外，一些努力探索了增加模型宽度以提高学习能力的好处。 塞格迪等人提出了带有初始模块的 GoogleNet，该模块在给定层的同一特征图上应用了不同尺度的卷积核（1 × 1、3 × 3 和 5 × 5）。 通过这种方式，它捕获了多尺度特征并将这些特征汇总在一起作为输出特征图。 该模型的更好版本后来开发了不同的卷积核选择设计，并引入了残差块。

上面介绍的网络结构都是为图像分类设计的。通常，这些在 ImageNet 上训练的模型被用作对象检测模型的初始化。然而，由于分类和检测任务之间的潜在冲突，直接将这个预训练模型从分类应用到检测是次优的。具体来说，i）分类需要大的感受野并希望保持空间不变性。因此，应用多个下采样操作（例如池化层）来降低特征图分辨率。生成的特征图分辨率低，空间不变，具有大的感受野。然而，在检测中，需要高分辨率的空间信息才能正确定位物体； ii) 分类对单个特征图进行预测，而检测需要具有多种表示的特征图来检测多个尺度的对象。为了弥合这两项任务之间的困难，Li 等人介绍了专为检测而设计的 DetNet。 DetNet 保留了高分辨率特征图，用于通过扩张卷积进行预测以增加感受野。此外，DetNet 在多尺度特征图上检测对象，提供了更丰富的信息。 DetNet 在大规模分类数据集上进行了预训练，而网络结构是为检测而设计的。

沙漏网络是另一种架构，它不是专门为图像分类而设计的。 沙漏网络首先出现在人体姿势识别任务中，它是一个完全卷积的结构，具有一系列沙漏模块。 沙漏模块首先通过一系列卷积层或池化层对输入图像进行下采样，然后通过反卷积操作对特征图进行上采样。 为了避免下采样阶段的信息丢失，在下采样和上采样功能之间使用了跳跃连接。 沙漏模块可以捕获局部和全局信息，因此非常适合对象检测。 目前，沙漏网络广泛用于最先进的检测框架。

## 3.4 建议框生成
提议生成在对象检测框架中起着非常重要的作用。 提议生成器生成一组矩形边界框，它们是潜在的对象。 然后将这些建议用于分类和定位细化。 我们将提议生成方法分为四类：传统的计算机视觉方法、基于锚点的监督学习方法、基于关键点的方法和其他方法。 值得注意的是，一级检测器和二级检测器都生成建议，主要区别在于两级检测器生成一组仅具有前景或背景信息的稀疏建议，而一级检测器则考虑每个区域 图像作为一个潜在的提议，并相应地估计每个位置潜在对象的类和边界框坐标。

### 3.4.1 传统视觉方法
这些方法使用基于低级线索（例如边缘、角、颜色等）的传统计算机视觉方法在图像中生成建议。这些技术可以分为三个原则：i）计算一个候选框； ii) 从原始图像中合并超像素； iii) 生成多个前景和背景片段；

基于**对象性分数**的方法预测每个候选框的对象性分数，测量它可能包含一个对象的可能性。 阿贝拉兹等人根据颜色对比度、边缘密度和显着性等视觉线索，通过分类为提案分配客观性分数。 拉图等人重新审视了 Arbelaez 等人的想法并引入了一种更有效的级联学习方法来对候选提案的客观性分数进行排名。

**超像素合并**基于合并从分割结果生成的超像素。 Selective Search 是一种基于合并超像素的提议生成算法。 它计算了分割方法生成的多个层次段，根据它们的视觉因素（颜色、区域等）进行合并，最后在合并的段上放置边界框。 马宁等人提出了一个类似的想法来合并超像素。 不同的是学习了合并函数的权重，合并过程是随机的。 与其他传统方法相比，选择性搜索因其效率和高召回率而被广泛应用于许多检测框架中。

**种子分割**从多个种子区域开始，并为每个种子生成前景和背景片段。 为了避免建立层次分割，CPMC 生成了一组用不同种子初始化的重叠段。 每个提议段都是二元（前景或背景）分割问题的解决方案。 Enreds 和 Hoiem 结合了 Selective Search 和 CPMC 的想法。 它从超像素开始，并将它们与新设计的功能合并。 这些合并的段被用作种子以生成更大的段，这类似于 CPMC。 但是，生成高质量的分割掩码非常耗时，并且不适用于大规模数据集。

这些传统计算机视觉方法的主要优点是它们非常简单，并且可以生成具有高召回率的建议（例如，在 Pascal VOC 等中等规模的数据集上）。 然而，这些方法主要基于低级视觉线索，如颜色或边缘。 它们不能与整个检测管道联合优化。 因此，他们无法利用大规模数据集的力量来改进表征学习。 在 MSCOCO 等具有挑战性的数据集上，由于这些限制，传统的计算机视觉方法难以生成高质量的建议。

### 3.4.2 基于anchor的方法
一大类监督提议生成器是基于锚的方法。他们根据预定义的锚点生成建议。任等人提议的区域提议网络 (RPN) 以基于深度卷积特征图的监督方式生成提议。网络使用 3 × 3 卷积滤波器在整个特征图上滑动。对于每个位置，考虑了不同大小和纵横比的 k 个锚点（或边界框的初始估计）。这些大小和比率允许匹配整个图像中不同比例的对象。基于地面实况绑定框，对象位置与最合适的锚点相匹配，以获得锚点估计的监督信号。从每个锚点中提取一个 256 维的特征向量，并将其输入两个兄弟分支——分类层和回归层。分类分支负责对对象性得分进行建模，而回归分支对四个实数值进行编码，以从原始锚点估计中细化边界框的位置。基于真实情况，每个锚点被预测为一个对象，或者只是分类分支的背景。后来SSD采用了RPN中类似anchors的思想，通过使用多尺度anchor来匹配对象。主要区别在于SSD为每个anchor proposal分配了分类概率，而RPN首先评估anchor proposal是前景还是背景，并在下一阶段进行分类。

尽管有良好的性能，但锚点先验是以启发式方式手动设计的具有多个尺度和纵横比。这些设计选择可能不是最优的，不同的数据集需要不同的锚设计策略。已经做出许多努力来改进锚的设计选择。张等人提出了基于 SSD 的 Single Shot Scale-invariant Face Detector (S3FD)，并带有精心设计的锚点来匹配对象。根据不同特征图的有效感受野，设计了不同的锚先验。朱等人介绍了一种通过扩大输入图像大小和减少锚步幅来匹配小对象的锚设计方法。谢等人提出了维度分解区域提议网络（DeRPN），它基于RPN分解了锚框的维度。 DeRPN 使用锚串机制来独立匹配对象的宽度和高度。这有助于匹配具有大规模方差的对象并减少搜索空间。

戈德拉蒂等人开发了 DeepProposals，它预测了低分辨率更深层特征图上的提议。然后将它们投影回高分辨率浅层特征图，在那里进一步细化。雷蒙等人通过使用 k 均值聚类从训练数据中学习先验来设计锚先验。后来，张等人引入了Single-Shot Refinement Neural Network (RefineDet) ，它分两步改进了手动定义的anchor。在第一步中，RefineDet 基于原始手工设计的锚点学习了一组定位偏移量，这些锚点通过学习到的偏移量进行了细化。在第二阶段，基于第一步中细化的锚点学习一组新的定位偏移，以进一步细化。这种级联优化框架以数据驱动的方式显着提高了锚点质量和最终预测精度。蔡等人提出了 Cascade R-CNN ，它采用了与 RefineDet 类似的想法，通过以级联方式提炼提议。杨等人将锚建模为由神经网络实现的函数，该函数是根据自定义锚计算的。与其他手动定义的方法相比，他们的方法 MetaAnchor 显示出全面的改进，但定制的锚点仍然是手动设计的。

### 3.4.3 基于关键点的方法
另一种生成提议的方法是基于关键点检测，它可以分为两大类：基于角点的方法和基于中心的方法。基于角的方法通过合并从特征图中学习的角对来预测边界框。 Denet 以概率的方式重新表述了目标检测问题。对于特征图上的每个点，Denet 对作为 4 个角类型对象（左上、右上、左下、右下）之一的分布进行建模，并在每个点上应用朴素贝叶斯分类器。对象的角来估计边界框的置信度分数。这种基于角点的算法消除了锚点的设计，成为产生高质量建议的更有效方法。后来基于 Denet，Law 和 Deng 提出了 CornerNet ，它直接对角的分类信息进行建模。 CornerNet 使用新颖的特征嵌入方法和角池层对左上角和右下角的信息进行建模，以正确匹配属于相同对象的关键点，在公共基准上获得最先进的结果。对于基于中心的方法，在特征图的每个位置上预测成为对象中心的概率，并且高度和宽度直接回归，没有任何锚先验。朱等人提出了一种无特征选择锚（FSAF）框架，该框架可以插入具有 FPN 结构的单级检测器中。在 FSAF 中，应用在线特征选择块来训练附加在特征金字塔每一层的多级基于中心的分支。在训练期间，FSAF 将每个对象动态分配到最合适的特征级别来训练基于中心的分支。类似于 FSAF，Zhou 等人提出了一种新的基于中心的框架，该框架基于没有 FPN 结构的单个沙漏网络。此外，他们将基于中心的方法应用于更高级别的问题，例如 3D 检测和人体姿势识别，并且都取得了最先进的结果。段等人提出了CenterNet，它结合了基于中心的方法和基于角的方法的思想。 CenterNet 首先通过角对预测边界框，然后预测初始预测的中心概率以拒绝简单的否定。与基线相比，CenterNet 获得了显着的改进。这些无锚方法形成了未来有希望的研究方向。

### 3.4.4 其他方法
还有一些其他的提议生成算法不是基于关键点或锚点，但也提供有竞争力的性能。 卢等人提出了 AZnet ，它自动关注高兴趣区域。 AZnet 采用了一种搜索策略，可自适应地将计算资源定向到可能包含对象的子区域。 对于每个区域，AZnet 预测了两个值：缩放指标和邻接分数。 缩放指标决定是否进一步划分这个可能包含较小对象的区域，邻接分数表示其对象性。 起点是整个图像，每个分割的子区域都以这种方式递归处理，直到缩放指示符太小。 与 RPN 的锚对象匹配方法相比，AZnet 更擅长匹配稀疏和小对象。

## 3.5 特征表示学习
特征表示学习是整个检测框架中的关键组成部分。 目标对象位于复杂的环境中，并且在比例和纵横比上有很大的差异。 需要训练对象的鲁棒性和判别性特征嵌入以获得良好的检测性能。 在本节中，我们将介绍用于对象检测的特征表示学习策略。 具体来说，我们确定了三类：多尺度特征学习、上下文推理和可变形特征学习。

### 3.5.1 多尺度特征学习
基于深度卷积网络的典型对象检测算法，例如 Fast R-CNN 和 Faster R-CNN ，仅使用单层的特征图来检测对象。然而，在单个特征图上检测大范围尺度和纵横比的对象非常具有挑战性。深度卷积网络在不同的层中学习层次特征，捕捉不同的尺度信息。具体而言，具有丰富空间信息的浅层特征具有更高的分辨率和更小的感受野，因此更适合检测小物体，而深层语义丰富的特征对光照、平移和更大的感受野具有更强的鲁棒性。场（但分辨率粗糙），更适合检测大型物体。在检测小物体时，需要高分辨率的表示，而这些物体的表示甚至可能无法在深层特征中使用，从而使小物体检测变得困难。提出了一些技术，例如扩张/空洞卷积 来避免下采样，并且即使在更深层也使用高分辨率信息。同时，在没有足够大的感受野的情况下，检测浅层中的大型物体也是非最佳的。因此，处理特征尺度问题已成为目标检测中的一个基本研究问题。解决多尺度特征学习问题的主要范式有四种：图像金字塔、预测金字塔、集成特征和特征金字塔。

![multi_scale](assets/multi_scale.png)

- 图像金字塔   
  一个直观的想法是将输入图像调整为多个不同的尺度（图像金字塔）并训练多个检测器，每个检测器负责一定范围的尺度 。在测试过程中，图像被调整到不同的比例，然后是多个检测器，并合并检测结果。这在计算上可能是昂贵的。刘等人首先学习了一个轻量级的尺度感知网络来调整图像大小，使所有对象都处于相似的尺度。接下来是学习单尺度检测器。辛格等阿尔。 对小物体检测进行了全面的实验。他们认为，学习一个单一尺度稳健的检测器来处理所有尺度的对象比学习具有图像金字塔的尺度相关检测器要困难得多。在他们的工作中，他们提出了一个新的框架图像金字塔尺度归一化（SNIP），它训练了多个尺度相关的检测器，每个检测器负责特定尺度的对象。

- 集成特征   
  另一种方法是通过组合多个层中的特征并基于新构建的地图进行最终预测来构建单个特征图。通过融合空间丰富的浅层特征和语义丰富的深层特征，新构建的特征包含丰富的信息，从而可以检测不同尺度的对象。这些组合通常是通过使用跳过连接 来实现的。由于不同层的特征范数具有很高的方差，因此需要进行特征归一化。贝尔等人提出了内-外网络（ION），它通过ROI池化从不同层裁剪区域特征，并结合这些多尺度区域特征进行最终预测。孔等阿尔提出了 HyperNet ，它采用了与 IoN 类似的想法。他们通过集成中间层和浅层特征来生成建议和检测对象，精心设计了高分辨率超特征图。反卷积层用于对深层特征图进行上采样，而批量归一化层用于在其工作中对输入 blob 进行归一化。构建的超特征图还可以隐式编码来自不同层的上下文信息。受到细粒度分类算法的启发，该算法集成了高阶表示而不是利用对象提议的简单一阶表示，Wang 等人提出了一个新的框架多尺度位置感知内核表示（MLKP），它捕获了提议特征的高阶统计数据并有效地生成了更具判别力的特征表示。组合特征表示更具描述性，并为分类和定位提供语义和空间信息。

- 预测金字塔   
  Liu 等人的 SSD 将来自多个层的粗略特征和精细特征结合在一起。在 SSD 中，预测是由多层进行的，其中每一层负责一定规模的对象。后来，许多努力 遵循这个原则来检测多尺度对象。杨等人还利用适当的特征图来生成一定比例的对象提议，并将这些特征图输入多个依赖于比例的分类器来预测对象。在他们的工作中，级联拒绝分类器学会了在早期阶段拒绝简单的背景建议，以加快检测速度。多尺度深度卷积神经网络（MSCNN）在多个特征图上应用反卷积层以提高它们的分辨率，后来这些细化的特征图被用来进行预测。刘等人提出了一个感受野块网络（RF-BNet），以通过感受野块（RFB块）增强鲁棒性和感受野。 RFB 块采用与初始模块类似的思想，它通过具有不同卷积核的多个分支从多个尺度和感受野中捕获特征，并最终将它们合并在一起。

- 特征金字塔    
  为了结合集成特征和预测金字塔的优势，Lin 等人提出了特征金字塔网络（FPN），它以自上而下的方式将不同尺度的特征与横向连接相结合，以构建一组尺度不变的特征图，并在这些特征金字塔上学习了多个尺度相关的分类器.具体来说，深层语义丰富的特征被用来加强浅层空间丰富的特征。这些自上而下和横向的特征通过逐元素求和或串联相结合，小卷积减少了维度。 FPN 在目标检测以及其他应用方面表现出显着改进，并在学习多尺度特征方面取得了最先进的成果。后来开发了 FPN 的许多变体，并对特征金字塔块进行了修改。孔等人和张等建立了具有横向连接的尺度不变特征图。与 FPN 不同，FPN 生成区域提议，然后是分类分类器，他们的方法省略了提议生成，因此比原始 FPN 更有效。任和 Jeong 等人开发了一种新颖的结构，该结构逐渐选择性地编码不同层特征之间的上下文信息。受超分辨率任务的启发，Zhou 等人使用新的变换块开发了高分辨率特征图，该块明确探索了跨多个检测尺度的尺度间一致性性质。

### 3.5.2 区域特征嵌入
对于两阶段检测器，区域特征编码是从提案中提取特征到固定长度特征向量的关键步骤。 在 R-CNN 中，Girshick 等人从整个图像中裁剪区域建议，并通过双线性插值将裁剪区域调整为固定大小的补丁（224 × 224），然后是深度卷积特征提取器。 他们的方法编码了高分辨率区域特征，但计算成本很高。

后来 Girshick 等人和 Ren 提出了 ROI 池化层来编码区域特征。 ROI Pooling 将每个区域划分为 n × n 个单元（例如默认为 7 × 7），只有具有最大信号的神经元才会在前馈阶段前进。这类似于最大池化，但跨越（可能）不同大小的区域。 ROI Pooling 从下采样的特征图中提取特征，因此难以处理小对象。 Dai 提出了 ROI Warping 层，它通过双线性插值对区域特征进行编码。由于 DCNN 中的下采样操作，原始图像中的对象位置和下采样的特征图可能会出现错位，这是 RoI Pooling 和 RoI Warping 层无法处理的。 He 等人没有像 ROI Warping 和 ROI Pooling 那样量化网格边界，提出了 ROI Align 层，它通过在每个网格内的部分采样位置进行双线性插值来解决量化问题。基于 ROI Align，Jiang 等人提出了 Precise ROI Pooing（PrROI Pooling），它避免了任何坐标量化，并且在边界框坐标上具有连续梯度。

为了增强下采样区域特征的空间信息，戴等人提出了位置敏感的 ROI Pooing (PSROI Pooling)，它保留了下采样特征的相对空间信息。生成的区域特征图的每个通道根据其相对空间位置仅对应于输入区域的一个子集通道。 Zhai 等人基于 PSROI Pooling提出了特征选择网络，通过利用子区域和纵横比之间的差异来学习鲁棒的区域特征。所提出的网络编码子区域和纵横比信息，这些信息被选择性地汇集起来，以通过轻量级头部来细化初始区域特征。

后来，更多的算法被提出来从不同的角度很好地编码区域特征。朱等人提出的 CoupleNet通过组合从 ROI 池化层和 PSROI 池化层生成的输出来提取区域特征。 ROI 池化层提取全局区域信息，但难以处理高遮挡的对象，而 PSROI 池化层更侧重于局部信息。 CoupleNet 通过元素求和增强了从 ROI Pooling 和 PSROI Pooling 生成的特征，并生成了更强大的特征。后来戴等人。提出了可变形 ROI 池化 ，它通过学习每个网格的偏移并将其添加到网格中心来概括对齐的 RoI 池化。子网格以常规 ROI 池化层开始以提取初始区域特征，提取的特征用于通过辅助网络回归偏移。 Deformable ROI Pooling 可以自动对图像内容进行建模，而不受固定感受野的约束

### 3.5.3 上下文推理
上下文信息在对象检测中起着重要作用。对象往往倾向于出现在特定的环境中，有时也与其他对象共存。对于每个例子，鸟类通常在天空中飞翔。有效地使用上下文信息可以帮助提高检测性能，特别是对于检测线索不足的对象（小对象、遮挡等）。学习对象与其周围上下文之间的关系可以提高检测器理解场景的能力。对于传统的对象检测算法，已经有一些探索上下文的努力，但是对于基于深度学习的对象检测，上下文还没有得到广泛的探索。这是因为卷积网络已经隐式地从层次特征表示中捕获了上下文信息。然而，最近的一些努力仍然试图利用上下文信息。一些工作甚至表明，在某些情况下，上下文信息甚至可能会损害检测性能。在本节中，我们从两个方面来回顾对象检测的上下文推理：全局上下文和区域上下文。

全局上下文推理是指从整个图像的上下文中学习。 与试图将图像中的特定区域分类为对象的传统检测器不同，这里的想法是使用上下文信息（即来自图像其余部分的信息）来对特定的感兴趣区域进行分类。 例如，从图像中检测棒球可能对传统检测器具有挑战性（因为它可能与其他运动的球混淆）； 但如果使用来自图像其余部分的上下文信息（例如棒球场、球员、球棒），则识别棒球球对象会变得更容易。

## 

# 4，学习策略

